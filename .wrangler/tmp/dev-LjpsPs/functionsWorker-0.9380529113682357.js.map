{
  "version": 3,
  "sources": ["../bundle-UETRbs/checked-fetch.js", "../bundle-F0376h/checked-fetch.js", "../../../functions/api/enhance.js", "../../../functions/api/pollinations-text.js", "../../../functions/api/scrape-url.js", "../../../functions/api/speech-to-text.js", "../../../functions/api/firecrawl.js", "../../../functions/api/multi-scrape.js", "../../../functions/api/phantom-scrape.js", "../../../functions/api/pollinations-search.js", "../../../functions/api/scraperapi.js", "../../../functions/api/scrapingant.js", "../../../functions/_middleware.js", "../pages-jGo0im/functionsRoutes-0.2772845736527274.mjs", "../../../../../../node_modules/wrangler/node_modules/path-to-regexp/src/index.ts", "../../../../../../node_modules/wrangler/templates/pages-template-worker.ts", "../../../../../../node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../../../node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-F0376h/middleware-insertion-facade.js", "../../../../../../node_modules/wrangler/templates/middleware/common.ts", "../bundle-F0376h/middleware-loader.entry.ts", "../../../../../../node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../../../node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-UETRbs/middleware-insertion-facade.js", "../../../../../../node_modules/wrangler/templates/middleware/common.ts", "../bundle-UETRbs/middleware-loader.entry.ts"],
  "sourceRoot": "/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/dev-LjpsPs",
  "sourcesContent": ["const urls = new Set();\n\nfunction checkURL(request, init) {\n\tconst url =\n\t\trequest instanceof URL\n\t\t\t? request\n\t\t\t: new URL(\n\t\t\t\t\t(typeof request === \"string\"\n\t\t\t\t\t\t? new Request(request, init)\n\t\t\t\t\t\t: request\n\t\t\t\t\t).url\n\t\t\t\t);\n\tif (url.port && url.port !== \"443\" && url.protocol === \"https:\") {\n\t\tif (!urls.has(url.toString())) {\n\t\t\turls.add(url.toString());\n\t\t\tconsole.warn(\n\t\t\t\t`WARNING: known issue with \\`fetch()\\` requests to custom HTTPS ports in published Workers:\\n` +\n\t\t\t\t\t` - ${url.toString()} - the custom port will be ignored when the Worker is published using the \\`wrangler deploy\\` command.\\n`\n\t\t\t);\n\t\t}\n\t}\n}\n\nglobalThis.fetch = new Proxy(globalThis.fetch, {\n\tapply(target, thisArg, argArray) {\n\t\tconst [request, init] = argArray;\n\t\tcheckURL(request, init);\n\t\treturn Reflect.apply(target, thisArg, argArray);\n\t},\n});\n", "const urls = new Set();\n\nfunction checkURL(request, init) {\n\tconst url =\n\t\trequest instanceof URL\n\t\t\t? request\n\t\t\t: new URL(\n\t\t\t\t\t(typeof request === \"string\"\n\t\t\t\t\t\t? new Request(request, init)\n\t\t\t\t\t\t: request\n\t\t\t\t\t).url\n\t\t\t\t);\n\tif (url.port && url.port !== \"443\" && url.protocol === \"https:\") {\n\t\tif (!urls.has(url.toString())) {\n\t\t\turls.add(url.toString());\n\t\t\tconsole.warn(\n\t\t\t\t`WARNING: known issue with \\`fetch()\\` requests to custom HTTPS ports in published Workers:\\n` +\n\t\t\t\t\t` - ${url.toString()} - the custom port will be ignored when the Worker is published using the \\`wrangler deploy\\` command.\\n`\n\t\t\t);\n\t\t}\n\t}\n}\n\nglobalThis.fetch = new Proxy(globalThis.fetch, {\n\tapply(target, thisArg, argArray) {\n\t\tconst [request, init] = argArray;\n\t\tcheckURL(request, init);\n\t\treturn Reflect.apply(target, thisArg, argArray);\n\t},\n});\n", "// functions/api/enhance.js\nexport async function onRequestPost(context) {\n    try {\n      // Parse the form data from the request\n      const formData = await context.request.formData();\n      const imageFile = formData.get('image');\n      const transformationsString = formData.get('transformations') || '{}';\n      let transformations;\n      \n      try {\n        transformations = JSON.parse(transformationsString);\n      } catch (e) {\n        transformations = {};\n      }\n      \n      // Access environment variables from Cloudflare Pages\n      const cloudName = context.env.CLOUDINARY_CLOUD_NAME;\n      const apiKey = context.env.CLOUDINARY_API_KEY;\n      const apiSecret = context.env.CLOUDINARY_API_SECRET;\n      \n      if (!cloudName || !apiKey || !apiSecret) {\n        return new Response(JSON.stringify({\n          success: false,\n          error: \"Missing Cloudinary credentials\"\n        }), {\n          status: 500,\n          headers: { \n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*'\n          }\n        });\n      }\n      \n      // Convert image file to base64 for Cloudinary upload\n      const arrayBuffer = await imageFile.arrayBuffer();\n      const buffer = new Uint8Array(arrayBuffer);\n      const base64Image = btoa(String.fromCharCode.apply(null, buffer));\n      const dataURI = `data:${imageFile.type};base64,${base64Image}`;\n      \n      // Generate timestamp and signature for Cloudinary\n      const timestamp = Math.round(new Date().getTime() / 1000);\n      const signature = await generateSignature(`timestamp=${timestamp}${apiSecret}`);\n      \n      // Create form for Cloudinary upload\n      const cloudinaryFormData = new FormData();\n      cloudinaryFormData.append('file', dataURI);\n      cloudinaryFormData.append('api_key', apiKey);\n      cloudinaryFormData.append('timestamp', timestamp);\n      cloudinaryFormData.append('signature', signature);\n      cloudinaryFormData.append('folder', 'dreamscape-ai-enhanced');\n      \n      // Upload image to Cloudinary\n      const uploadResponse = await fetch(`https://api.cloudinary.com/v1_1/${cloudName}/image/upload`, {\n        method: 'POST',\n        body: cloudinaryFormData\n      });\n      \n      if (!uploadResponse.ok) {\n        const errorData = await uploadResponse.json();\n        return new Response(JSON.stringify({\n          success: false,\n          error: \"Failed to upload to Cloudinary\",\n          details: errorData\n        }), {\n          status: 500,\n          headers: { \n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*'\n          }\n        });\n      }\n      \n      const uploadResult = await uploadResponse.json();\n      \n      // Build transformation URL\n      const transformationParts = [];\n      \n      // Process all transformations\n      Object.entries(transformations).forEach(([key, value]) => {\n        if (value === true) {\n          transformationParts.push(key);\n        } else {\n          transformationParts.push(`${key}:${value}`);\n        }\n      });\n      \n      // Ensure we have basic sizing if nothing else\n      if (transformationParts.length === 0) {\n        transformationParts.push('c_fill,w_768,h_768');\n        transformationParts.push('q_auto,f_auto');\n      } else {\n        // Add quality optimization to all transformations\n        transformationParts.push('q_auto,f_auto');\n      }\n      \n      // Build the final URL\n      const transformationString = transformationParts.join('/');\n      const enhancedImageUrl = `https://res.cloudinary.com/${cloudName}/image/upload/${transformationString}/${uploadResult.public_id}`;\n      \n      return new Response(JSON.stringify({\n        success: true,\n        original: uploadResult.secure_url,\n        enhanced: enhancedImageUrl,\n        public_id: uploadResult.public_id\n      }), {\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    } catch (error) {\n      console.error(\"Error:\", error);\n      return new Response(JSON.stringify({ \n        success: false, \n        error: error.message \n      }), {\n        status: 500,\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    }\n  }\n  \n  // Helper function to generate signature\n  async function generateSignature(string) {\n    // Convert string to an Uint8Array to digest\n    const encoder = new TextEncoder();\n    const data = encoder.encode(string);\n    \n    // Hash the data using SHA-1\n    const hashBuffer = await crypto.subtle.digest('SHA-1', data);\n    \n    // Convert to hex string\n    const hashArray = Array.from(new Uint8Array(hashBuffer));\n    const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');\n    \n    return hashHex;\n  }", "// functions/api/pollinations-text.js\nexport async function onRequestPost(context) {\n  try {\n    console.log(\"Pollinations Text API endpoint called with POST method\");\n    \n    // Parse the request body\n    const requestBody = await context.request.json();\n    const { model, prompt, system, context: contextText, max_tokens } = requestBody;\n    \n    if (!prompt) {\n      return new Response(JSON.stringify({\n        success: false,\n        error: \"Missing 'prompt' parameter in request body\"\n      }), {\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    }\n    \n    console.log(\"Using model for text generation:\", model || \"openai\");\n    \n    // Determine if we should use POST or GET format based on model\n    let responseText;\n    let responseIsJson = false;\n    \n    if (model === 'searchgpt') {\n      // For searchgpt, use GET endpoint format\n      const encodedPrompt = encodeURIComponent(prompt);\n      const seed = Math.floor(Math.random() * 1000);\n      const searchUrl = `https://text.pollinations.ai/${encodedPrompt}?model=searchgpt&seed=${seed}&json=true`;\n      \n      console.log(\"Using GET endpoint for searchgpt:\", searchUrl);\n      \n      const pollinationsResponse = await fetch(searchUrl);\n      \n      if (!pollinationsResponse.ok) {\n        throw new Error(`Pollinations API returned ${pollinationsResponse.status}: ${pollinationsResponse.statusText}`);\n      }\n      \n      // SearchGPT always returns JSON\n      responseText = await pollinationsResponse.text();\n      responseIsJson = true;\n    } else {\n      // For all other models, use the simpler GET approach which is more reliable\n      const encodedPrompt = encodeURIComponent(prompt);\n      let apiUrl = `https://text.pollinations.ai/${encodedPrompt}?model=${model || 'openai'}`;\n      \n      // Add system prompt as a parameter if provided\n      if (system) {\n        const encodedSystem = encodeURIComponent(system);\n        apiUrl += `&system=${encodedSystem}`;\n      }\n      \n      // Add max tokens if provided\n      if (max_tokens) {\n        apiUrl += `&max_tokens=${max_tokens}`;\n      }\n      \n      console.log(\"Using GET endpoint for text generation:\", apiUrl);\n      \n      const pollinationsResponse = await fetch(apiUrl);\n      \n      if (!pollinationsResponse.ok) {\n        throw new Error(`Pollinations API returned ${pollinationsResponse.status}: ${pollinationsResponse.statusText}`);\n      }\n      \n      // Check content type to determine if response is JSON or text\n      const contentType = pollinationsResponse.headers.get('content-type') || '';\n      responseIsJson = contentType.includes('application/json');\n      \n      // Get response as text\n      responseText = await pollinationsResponse.text();\n    }\n    \n    console.log(\"Pollinations API response received successfully\");\n    console.log(\"Response is JSON:\", responseIsJson);\n    \n    // Construct our response based on whether we received JSON or plain text\n    let resultData = {\n      success: true,\n      model: model || 'openai'\n    };\n    \n    if (responseIsJson) {\n      try {\n        // Parse the JSON response\n        const jsonData = JSON.parse(responseText);\n        \n        // Extract the text from the appropriate JSON structure\n        if (jsonData.text) {\n          resultData.text = jsonData.text;\n        } else if (jsonData.content) {\n          resultData.text = jsonData.content;\n        } else if (jsonData.choices && jsonData.choices[0] && jsonData.choices[0].message) {\n          resultData.text = jsonData.choices[0].message.content;\n        } else {\n          // If we can't find the expected text fields, include the whole response\n          resultData.text = JSON.stringify(jsonData);\n        }\n        \n        // Include the raw JSON for debugging\n        resultData.raw = jsonData;\n      } catch (parseError) {\n        console.error(\"Error parsing JSON response:\", parseError);\n        // If JSON parsing fails, just use the raw text\n        resultData.text = responseText;\n        resultData.parseError = parseError.message;\n      }\n    } else {\n      // For plain text responses, just use the text directly\n      resultData.text = responseText;\n    }\n    \n    // Return our response\n    return new Response(JSON.stringify(resultData), {\n      headers: { \n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      }\n    });\n    \n  } catch (error) {\n    console.error(\"Error in Pollinations Text API endpoint:\", error);\n    \n    return new Response(JSON.stringify({\n      success: false,\n      error: error.message || \"Unknown error occurred\"\n    }), {\n      status: 500,\n      headers: { \n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      }\n    });\n  }\n} ", "// functions/api/scrape-url.js\n// Unified endpoint for web scraping using various services\n\nexport async function onRequestPost(context) {\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    // Parse request body\n    const body = await context.request.json();\n    const { url } = body;\n\n    if (!url) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'URL is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`Scraping URL: ${url}`);\n\n    // First try PhantomJS scraping\n    try {\n      const phantomScrapeUrl = new URL(context.request.url);\n      phantomScrapeUrl.pathname = '/api/phantom-scrape';\n      \n      const phantomResponse = await fetch(phantomScrapeUrl, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ url })\n      });\n      \n      if (phantomResponse.ok) {\n        const phantomData = await phantomResponse.json();\n        \n        if (phantomData.success && phantomData.content) {\n          console.log(`Successfully scraped ${url} with PhantomJS`);\n          return new Response(\n            JSON.stringify({ \n              success: true, \n              content: phantomData.content,\n              title: phantomData.title || url,\n              source: 'phantomjs'\n            }),\n            { headers }\n          );\n        }\n      }\n    } catch (phantomError) {\n      console.error(`PhantomJS scraping failed for ${url}: ${phantomError.message}`);\n    }\n\n    // Try multi-scrape as fallback\n    try {\n      const multiScrapeUrl = new URL(context.request.url);\n      multiScrapeUrl.pathname = '/api/multi-scrape';\n      \n      const multiResponse = await fetch(multiScrapeUrl, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ url })\n      });\n      \n      if (multiResponse.ok) {\n        const multiData = await multiResponse.json();\n        \n        if (multiData.success && multiData.content) {\n          console.log(`Successfully scraped ${url} with multi-scrape`);\n          return new Response(\n            JSON.stringify({ \n              success: true, \n              content: multiData.content,\n              title: multiData.title || url,\n              source: multiData.source || 'multi-scrape'\n            }),\n            { headers }\n          );\n        }\n      }\n    } catch (multiError) {\n      console.error(`Multi-scrape failed for ${url}: ${multiError.message}`);\n    }\n\n    // Try individual services as fallbacks\n    const services = [\n      { name: 'scraperapi', path: '/api/scraperapi' },\n      { name: 'scrapingant', path: '/api/scrapingant' },\n      { name: 'firecrawl', path: '/api/firecrawl' }\n    ];\n\n    for (const service of services) {\n      try {\n        const serviceUrl = new URL(context.request.url);\n        serviceUrl.pathname = service.path;\n        \n        const serviceResponse = await fetch(serviceUrl, {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({ url })\n        });\n        \n        if (serviceResponse.ok) {\n          const serviceData = await serviceResponse.json();\n          \n          if (serviceData.success && serviceData.content) {\n            console.log(`Successfully scraped ${url} with ${service.name}`);\n            return new Response(\n              JSON.stringify({ \n                success: true, \n                content: serviceData.content,\n                title: serviceData.title || url,\n                source: service.name\n              }),\n              { headers }\n            );\n          }\n        }\n      } catch (serviceError) {\n        console.error(`${service.name} scraping failed for ${url}: ${serviceError.message}`);\n      }\n    }\n\n    // If all services fail, generate a synthetic response\n    console.log(`All scraping services failed for ${url}, generating synthetic content`);\n    \n    // Use Pollinations API to generate synthetic content\n    try {\n      const pollinationsUrl = new URL(context.request.url);\n      pollinationsUrl.pathname = '/api/pollinations-text';\n      \n      const pollinationsResponse = await fetch(pollinationsUrl, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          model: 'openai',\n          prompt: `Generate plausible, detailed content about what might be found at the URL: ${url}`,\n          system: \"You are a web content generator. Create plausible, structured content (in markdown format) that might be found at the given URL. Base your generation on the URL structure, domain name, and any context clues. Include headings, lists, and other formatting as appropriate.\",\n          max_tokens: 1000\n        })\n      });\n      \n      const pollinationsData = await pollinationsResponse.json();\n      \n      if (pollinationsData.success && pollinationsData.text) {\n        return new Response(\n          JSON.stringify({ \n            success: true, \n            content: pollinationsData.text,\n            title: `Generated content for ${url}`,\n            source: 'synthetic',\n            synthetic: true\n          }),\n          { headers }\n        );\n      }\n    } catch (pollinationsError) {\n      console.error(`Failed to generate synthetic content: ${pollinationsError.message}`);\n    }\n\n    // If even synthetic generation fails\n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: 'All scraping services failed',\n        url\n      }),\n      { status: 500, headers }\n    );\n\n  } catch (error) {\n    console.error(`Error scraping URL: ${error}`);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message \n      }),\n      { status: 500, headers }\n    );\n  }\n} ", "// functions/api/speech-to-text.js\nexport async function onRequestPost(context) {\n  try {\n    console.log(\"Speech-to-text API endpoint called with POST method\");\n    \n    // Get the Watson credentials from environment variables\n    const watsonApiKey = context.env.WATSON_API_KEY;\n    const watsonUrl = 'https://api.au-syd.speech-to-text.watson.cloud.ibm.com/v1/recognize';\n    \n    console.log(\"Watson API Key available:\", !!watsonApiKey);\n    console.log(\"Environment variables available:\", Object.keys(context.env).join(\", \"));\n    \n    if (!watsonApiKey) {\n      return new Response(JSON.stringify({\n        success: false,\n        error: \"Missing Watson API Key in environment variables\",\n        availableVars: Object.keys(context.env).length\n      }), {\n        status: 200, // Return 200 to avoid CORS issues\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    }\n    \n    // Get the audio data from the request\n    const contentType = context.request.headers.get('Content-Type');\n    const audioData = await context.request.arrayBuffer();\n    \n    console.log(\"Received audio data of size:\", audioData.byteLength, \"bytes\");\n    console.log(\"Content-Type:\", contentType);\n    \n    // Only reject extremely small audio data (just enough to verify it's not empty)\n    if (audioData.byteLength < 100) {\n      console.log(\"Audio data too small, likely empty or corrupt\");\n      return new Response(JSON.stringify({\n        success: true,\n        results: { results: [] } // Return empty results rather than error\n      }), {\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    }\n    \n    // Create headers for Watson API\n    const watsonHeaders = new Headers();\n    // Watson is very picky about the exact content-type format (spaces after semicolons, no endian parameter)\n    watsonHeaders.append('Content-Type', 'audio/l16; rate=16000; channels=1');\n    watsonHeaders.append('Authorization', `Basic ${btoa('apikey:' + watsonApiKey)}`);\n    watsonHeaders.append('Accept', 'application/json');\n    \n    // Add Watson-specific parameters\n    const watsonUrlWithParams = new URL(watsonUrl);\n    watsonUrlWithParams.searchParams.append('model', 'en-AU_BroadbandModel'); // Changed back to AU model for key compatibility\n    watsonUrlWithParams.searchParams.append('smart_formatting', 'true');\n    watsonUrlWithParams.searchParams.append('word_confidence', 'true');\n    watsonUrlWithParams.searchParams.append('inactivity_timeout', '5'); // Lower inactivity timeout (default is 30)\n    watsonUrlWithParams.searchParams.append('max_alternatives', '3'); // Get more alternatives\n    \n    console.log(\"Sending request to Watson API:\", watsonUrlWithParams.toString());\n    console.log(\"Watson model: en-AU_BroadbandModel, settings: inactivity_timeout=5, max_alternatives=3\");\n    \n    try {\n      // Forward request to Watson\n      const watsonResponse = await fetch(watsonUrlWithParams.toString(), {\n        method: 'POST',\n        headers: watsonHeaders,\n        body: audioData\n      });\n      \n      // Get Watson's response\n      const responseText = await watsonResponse.text();\n      let parsedResponse;\n      \n      try {\n        parsedResponse = JSON.parse(responseText);\n        console.log(\"Watson raw response:\", JSON.stringify(parsedResponse).substring(0, 200) + \"...\");\n      } catch (parseError) {\n        console.log(\"Failed to parse Watson response:\", responseText.substring(0, 200));\n        parsedResponse = { results: [] };\n      }\n      \n      if (!watsonResponse.ok) {\n        console.log(\"Watson API error:\", watsonResponse.status, responseText);\n        \n        // Handle 400 errors specially (usually bad audio format or silent audio)\n        if (watsonResponse.status === 400) {\n          return new Response(JSON.stringify({\n            success: true,\n            results: { results: [] } // Return empty results rather than error\n          }), {\n            headers: { \n              'Content-Type': 'application/json',\n              'Access-Control-Allow-Origin': '*'\n            }\n          });\n        }\n        \n        return new Response(JSON.stringify({\n          success: false,\n          error: `Watson API error: ${watsonResponse.status}`,\n          details: responseText\n        }), {\n          status: 200, // Return 200 status but with error flag in response body\n          headers: { \n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin': '*'\n          }\n        });\n      }\n      \n      // Return the transcription results\n      console.log(\"Watson API success, returning results\");\n      \n      // Check if we have any results\n      const hasResults = parsedResponse && \n                        parsedResponse.results && \n                        parsedResponse.results.length > 0 && \n                        parsedResponse.results[0].alternatives && \n                        parsedResponse.results[0].alternatives.length > 0;\n      \n      if (hasResults) {\n        console.log(\"Detected transcript:\", parsedResponse.results[0].alternatives[0].transcript);\n      } else {\n        console.log(\"No speech detected in audio\");\n      }\n      \n      return new Response(JSON.stringify({\n        success: true,\n        results: parsedResponse\n      }), {\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    } catch (fetchError) {\n      console.error(\"Fetch error when calling Watson API:\", fetchError);\n      return new Response(JSON.stringify({\n        success: false,\n        error: \"Error connecting to Watson API\",\n        details: fetchError.message\n      }), {\n        status: 200, // Return 200 instead of 500 to avoid triggering CORS issues\n        headers: { \n          'Content-Type': 'application/json',\n          'Access-Control-Allow-Origin': '*'\n        }\n      });\n    }\n    \n  } catch (error) {\n    console.error(\"Error in speech-to-text function:\", error);\n    return new Response(JSON.stringify({\n      success: false,\n      error: error.message,\n      stack: error.stack\n    }), {\n      status: 200, // Return 200 instead of 500 to avoid triggering CORS issues\n      headers: { \n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      }\n    });\n  }\n}\n\n// Add CORS preflight handler\nexport async function onRequestOptions() {\n  console.log(\"Speech-to-text API endpoint called with OPTIONS method\");\n  return new Response(null, {\n    headers: {\n      'Access-Control-Allow-Origin': '*',\n      'Access-Control-Allow-Methods': 'POST, OPTIONS',\n      'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n      'Access-Control-Max-Age': '86400'\n    }\n  });\n} ", "// functions/api/firecrawl.js\nexport async function onRequest(context) {\n  // CORS headers\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    if (context.request.method !== 'POST') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Method not allowed' }),\n        { status: 405, headers }\n      );\n    }\n\n    // Get URL and options from request body\n    const body = await context.request.json();\n    const { url, renderJs } = body;\n\n    if (!url) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'URL is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`FireCrawl scraping: ${url}`);\n\n    // Get API key from environment\n    const apiKey = context.env.FIRECRAWL_API_KEY;\n    if (!apiKey) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'FireCrawl API key not configured' }),\n        { status: 500, headers }\n      );\n    }\n\n    // Make POST request to FireCrawl API\n    console.log(`Calling FireCrawl API for ${url}`);\n    \n    const response = await fetch('https://api.firecrawl.dev/v1/crawl', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${apiKey}`\n      },\n      body: JSON.stringify({\n        url: url,\n        javascript: renderJs === true,\n        markdown: true,     // Get markdown formatted content\n        elements: true,     // Get page elements\n        wait_for: 2000      // Wait for 2 seconds for JavaScript to execute\n      })\n    });\n    \n    if (!response.ok) {\n      const errorText = await response.text();\n      console.error(`FireCrawl API error (${response.status}): ${errorText}`);\n      return new Response(\n        JSON.stringify({ \n          success: false, \n          error: `FireCrawl API returned ${response.status} ${response.statusText}` \n        }),\n        { status: response.status, headers }\n      );\n    }\n    \n    // Get content from response\n    const data = await response.json();\n    \n    if (!data.success) {\n      return new Response(\n        JSON.stringify({ \n          success: false, \n          error: data.error || 'FireCrawl crawling failed' \n        }),\n        { status: 400, headers }\n      );\n    }\n    \n    // Extract the content - prefer markdown, fall back to text or HTML\n    const content = data.data?.markdown || data.data?.text || data.data?.html || '';\n    \n    return new Response(\n      JSON.stringify({\n        success: true,\n        content: content,\n        title: data.data?.title || '',\n        service: 'firecrawl',\n        raw: JSON.stringify(data).substring(0, 500) // Include first 500 chars of raw response for debugging\n      }),\n      { headers }\n    );\n  } catch (error) {\n    console.error('FireCrawl scraping error:', error);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message || 'Unknown error during FireCrawl scraping' \n      }),\n      { status: 500, headers }\n    );\n  }\n} ", "export async function onRequest(context) {\n  // CORS headers to allow requests from the frontend\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    // Verify the request is a POST\n    if (context.request.method !== 'POST') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Method not allowed' }),\n        { status: 405, headers }\n      );\n    }\n\n    // Get the request body\n    const body = await context.request.json();\n    const { url: targetUrl, renderJs } = body;\n\n    // Validate URL\n    if (!targetUrl) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'URL is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`Multi-service scraping: ${targetUrl}`);\n\n    // Try each scraping service in sequence until one succeeds\n    const services = [\n      { name: 'phantomjs', path: '/api/phantom-scrape' },\n      { name: 'scraperapi', path: '/api/scraperapi' },\n      { name: 'scrapingant', path: '/api/scrapingant' },\n      { name: 'firecrawl', path: '/api/firecrawl' }\n    ];\n\n    let lastError = null;\n    let serviceResults = [];\n\n    // Try each service\n    for (const service of services) {\n      try {\n        console.log(`Trying ${service.name} service...`);\n        \n        // Make a request to the appropriate service endpoint\n        let serviceUrl;\n        if (context.request.url.includes('localhost') || context.request.url.includes('127.0.0.1')) {\n          // Local development\n          serviceUrl = `http://${context.request.headers.get('host')}${service.path}`;\n        } else {\n          // Production environment\n          const url = new URL(context.request.url);\n          serviceUrl = `${url.protocol}//${url.host}${service.path}`;\n        }\n        \n        console.log(`Calling service at: ${serviceUrl}`);\n        const serviceResponse = await fetch(serviceUrl, {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify({\n            url: targetUrl,\n            renderJs: renderJs\n          })\n        });\n        \n        if (serviceResponse.ok) {\n          const serviceData = await serviceResponse.json();\n          \n          if (serviceData.success && serviceData.content) {\n            console.log(`${service.name} service succeeded with ${serviceData.content.length} chars of content`);\n            \n            // If the service succeeded, return its response\n            return new Response(\n              JSON.stringify({\n                success: true,\n                content: serviceData.content,\n                service: service.name,\n                allResults: serviceResults\n              }),\n              { headers }\n            );\n          } else {\n            // Service call was successful but content extraction failed\n            serviceResults.push({\n              service: service.name,\n              success: false,\n              error: serviceData.error || 'No content returned'\n            });\n            console.log(`${service.name} service failed: ${serviceData.error || 'No content returned'}`);\n          }\n        } else {\n          // Service call failed\n          const errorText = await serviceResponse.text();\n          serviceResults.push({\n            service: service.name,\n            success: false,\n            error: `${serviceResponse.status} ${serviceResponse.statusText}: ${errorText}`\n          });\n          console.log(`${service.name} service failed with status ${serviceResponse.status}: ${errorText}`);\n        }\n      } catch (serviceError) {\n        // Error occurred while calling the service\n        serviceResults.push({\n          service: service.name,\n          success: false,\n          error: serviceError.message\n        });\n        lastError = serviceError;\n        console.error(`Error calling ${service.name} service:`, serviceError);\n      }\n    }\n\n    // If we got here, all services failed\n    console.error('All scraping services failed');\n    \n    return new Response(\n      JSON.stringify({\n        success: false,\n        error: 'All scraping services failed',\n        lastError: lastError?.message,\n        serviceResults: serviceResults\n      }),\n      { status: 500, headers }\n    );\n  } catch (error) {\n    console.error('Multi-service scraping error:', error);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message || 'Unknown error during multi-service scraping' \n      }),\n      { status: 500, headers }\n    );\n  }\n} ", "export async function onRequest(context) {\n  // CORS headers\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    if (context.request.method !== 'POST') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Method not allowed' }),\n        { status: 405, headers }\n      );\n    }\n\n    // Get URL and options from request body\n    const body = await context.request.json();\n    const { url, renderJs } = body;\n\n    if (!url) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'URL is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`PhantomJS Cloud scraping: ${url}`);\n\n    // Get API key from environment\n    const apiKey = context.env.PHANTOMJSCLOUD_API_KEY;\n    if (!apiKey) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'PhantomJS Cloud API key not configured' }),\n        { status: 500, headers }\n      );\n    }\n\n    // PhantomJS Cloud API URL (updated to v2)\n    const apiUrl = `https://phantomjscloud.com/api/browser/v2/${apiKey}/`;\n    \n    console.log(`Calling PhantomJS Cloud API: ${apiUrl}`);\n    console.log(`URL to scrape: ${url}`); // Log the URL to verify it's not null\n    \n    // Updated approach using the request parameter in JSON format\n    try {\n      // Create a request following the v2 API format\n      const requestData = {\n        url: url,\n        renderType: renderJs ? 'html' : 'plainText',\n        outputAsJson: true,\n        requestSettings: {\n          maxWait: 30000,\n          waitInterval: 1000,\n          ignoreImages: true,\n          disableJavascript: !renderJs\n        },\n        renderSettings: {\n          viewport: {\n            width: 1280,\n            height: 1024\n          },\n          emulateMedia: \"screen\",\n          suppressJavascript: !renderJs\n        }\n      };\n      \n      console.log(`PhantomJS request: ${JSON.stringify(requestData, null, 2)}`);\n      \n      // Make the API request with the correct format\n      const response = await fetch(apiUrl, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          request: requestData // This is key - the v2 API expects a 'request' parameter\n        })\n      });\n      \n      // Log response status\n      console.log(`PhantomJS Cloud API response status: ${response.status}`);\n      \n      if (!response.ok) {\n        console.error(`PhantomJS API error: ${response.status} ${response.statusText}`);\n        const errorText = await response.text().catch(e => 'Could not read error response');\n        console.error(`Error details: ${errorText}`);\n        \n        // Try fallback approach with GET format \n        console.log('Trying fallback with GET request...');\n        const fallbackUrl = `${apiUrl}?url=${encodeURIComponent(url)}&renderType=${renderJs ? 'html' : 'plainText'}`;\n        \n        const fallbackResponse = await fetch(fallbackUrl);\n        if (!fallbackResponse.ok) {\n          return new Response(\n            JSON.stringify({ \n              success: false, \n              error: `PhantomJS Cloud API failed: ${response.status} ${response.statusText}`,\n              details: errorText\n            }),\n            { status: response.status, headers }\n          );\n        }\n        \n        return handlePhantomJsResponse(fallbackResponse, renderJs, headers);\n      }\n      \n      return handlePhantomJsResponse(response, renderJs, headers);\n      \n    } catch (error) {\n      console.error('PhantomJS Cloud API error:', error);\n      return new Response(\n        JSON.stringify({ \n          success: false, \n          error: error.message || 'Unknown error during PhantomJS scraping' \n        }),\n        { status: 500, headers }\n      );\n    }\n  } catch (error) {\n    console.error('PhantomJS Cloud scraping error:', error);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message || 'Unknown error during PhantomJS scraping' \n      }),\n      { status: 500, headers }\n    );\n  }\n}\n\n// Helper function to handle PhantomJS response\nasync function handlePhantomJsResponse(response, renderJs, headers) {\n  // Check if response is JSON or plain text\n  const contentType = response.headers.get('content-type');\n  \n  let data;\n  let content = '';\n  \n  if (contentType && contentType.includes('application/json')) {\n    data = await response.json();\n    \n    // Extract content from the JSON response\n    if (data && data.content) {\n      // New API format\n      content = data.content;\n    } else if (data && data.pageContent) {\n      // For backward compatibility\n      content = data.pageContent;\n    } else {\n      // Fallback\n      content = JSON.stringify(data);\n    }\n  } else {\n    // Plain text/HTML response\n    content = await response.text();\n  }\n  \n  // Process the content\n  let processedContent = content;\n  \n  if (renderJs && (content.includes('<html') || content.includes('<body'))) {\n    // Simple HTML cleanup \n    processedContent = content\n      .replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, '')\n      .replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, '')\n      .replace(/<head\\b[^<]*(?:(?!<\\/head>)<[^<]*)*<\\/head>/gi, '')\n      .replace(/<nav\\b[^<]*(?:(?!<\\/nav>)<[^<]*)*<\\/nav>/gi, '')\n      .replace(/<footer\\b[^<]*(?:(?!<\\/footer>)<[^<]*)*<\\/footer>/gi, '');\n      \n    // Extract main content\n    const mainMatch = processedContent.match(/<main[^>]*>([\\s\\S]*?)<\\/main>/i) ||\n                      processedContent.match(/<article[^>]*>([\\s\\S]*?)<\\/article>/i) ||\n                      processedContent.match(/<div[^>]*id=[\"']?content[\"']?[^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                      processedContent.match(/<div[^>]*class=[\"']?content[\"']?[^>]*>([\\s\\S]*?)<\\/div>/i);\n    \n    if (mainMatch && mainMatch[1]) {\n      // Found main content\n      processedContent = mainMatch[1]\n        .replace(/<[^>]*>/g, ' ')       // Replace tags with spaces\n        .replace(/\\s+/g, ' ')           // Normalize whitespace\n        .trim();\n    } else {\n      // No main content found, remove all HTML tags\n      processedContent = processedContent\n        .replace(/<[^>]*>/g, ' ')       // Replace tags with spaces\n        .replace(/\\s+/g, ' ')           // Normalize whitespace\n        .trim();\n    }\n  }\n  \n  return new Response(\n    JSON.stringify({\n      success: true,\n      content: processedContent,\n      service: 'phantomjs',\n      raw: typeof content === 'string' ? content.substring(0, 500) + (content.length > 500 ? '...' : '') : JSON.stringify(data || {}).substring(0, 500)\n    }),\n    { headers }\n  );\n} ", "// functions/api/pollinations-search.js\nexport async function onRequest(context) {\n  // CORS headers to allow requests from the frontend\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    // Verify the request is a POST\n    if (context.request.method !== 'POST') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Method not allowed' }),\n        { status: 405, headers }\n      );\n    }\n\n    // Get the request body\n    const body = await context.request.json();\n    const { query } = body;\n\n    // Validate query\n    if (!query) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Search query is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`Pollinations searchgpt query: ${query}`);\n\n    // Prepare query - ensure it starts with \"research\" for better results\n    const enhancedQuery = query.toLowerCase().startsWith('research') ? query : `research ${query}`;\n    const encodedQuery = encodeURIComponent(enhancedQuery);\n    \n    // Use a fixed seed that's known to work (from screenshot: 924)\n    const seed = 924;\n    \n    // Call Pollinations searchgpt API with GET format\n    const searchUrl = `https://text.pollinations.ai/${encodedQuery}?model=searchgpt&seed=${seed}&json=true`;\n    console.log(`Calling Pollinations API: ${searchUrl}`);\n    \n    const searchResponse = await fetch(searchUrl, {\n      headers: {\n        'Accept': 'application/json',\n      }\n    });\n    \n    if (!searchResponse.ok) {\n      throw new Error(`Pollinations searchgpt API returned ${searchResponse.status}: ${searchResponse.statusText}`);\n    }\n    \n    // Get response text first for debug purposes\n    const responseText = await searchResponse.text();\n    console.log(\"Raw response text:\", responseText);\n    \n    let searchResult;\n    try {\n      searchResult = JSON.parse(responseText);\n    } catch (err) {\n      console.error(\"Error parsing response JSON:\", err);\n      throw new Error(\"Failed to parse response from Pollinations API\");\n    }\n    \n    console.log(\"Search result structure:\", Object.keys(searchResult));\n    \n    // Extract URLs from the search results\n    let urls = [];\n    \n    // Check for urls directly in the response\n    if (searchResult.urls && Array.isArray(searchResult.urls)) {\n      console.log(\"Found urls array in root of response\");\n      urls = searchResult.urls.map(item => {\n        if (typeof item === 'string') {\n          // Handle case where url is just a string\n          return {\n            title: item,\n            url: item\n          };\n        } else {\n          // Handle case where url is an object with title, url, etc.\n          return {\n            title: item.title || 'No title',\n            url: item.url || item,\n            snippet: item.snippet\n          };\n        }\n      });\n    } else {\n      // This is a fallback for nested structures\n      // Find the first key that contains an array (should be the search results)\n      const resultsKey = Object.keys(searchResult).find(key => \n        Array.isArray(searchResult[key]) && \n        searchResult[key].length > 0\n      );\n      \n      if (resultsKey && searchResult[resultsKey]) {\n        urls = searchResult[resultsKey].map(item => {\n          if (typeof item === 'string') {\n            return {\n              title: item,\n              url: item\n            };\n          } else {\n            return {\n              title: item.title || 'No title',\n              url: item.url || item,\n              snippet: item.snippet\n            };\n          }\n        });\n      }\n    }\n    \n    console.log(`Found ${urls.length} URLs in search results:`, urls);\n    \n    return new Response(\n      JSON.stringify({ \n        success: true, \n        urls,\n        rawContent: JSON.stringify(searchResult)\n      }),\n      { headers }\n    );\n  } catch (error) {\n    console.error('Pollinations searchgpt error:', error);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message\n      }),\n      { status: 500, headers }\n    );\n  }\n} ", "export async function onRequest(context) {\n  // CORS headers\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    if (context.request.method !== 'POST') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Method not allowed' }),\n        { status: 405, headers }\n      );\n    }\n\n    // Get URL and options from request body\n    const body = await context.request.json();\n    const { url, renderJs } = body;\n\n    if (!url) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'URL is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`ScraperAPI scraping: ${url}`);\n\n    // Get API key from environment\n    const apiKey = context.env.SCRAPERAI_API_KEY;\n    if (!apiKey) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'ScraperAPI key not configured' }),\n        { status: 500, headers }\n      );\n    }\n\n    // Construct ScraperAPI URL (using GET request format)\n    const apiUrl = `http://api.scraperapi.com/?api_key=${apiKey}&url=${encodeURIComponent(url)}${renderJs ? '&render=true' : ''}`;\n    \n    console.log(`Calling ScraperAPI: ${apiUrl}`);\n    \n    // Make a GET request to ScraperAPI\n    const response = await fetch(apiUrl);\n    \n    if (!response.ok) {\n      const errorText = await response.text();\n      console.error(`ScraperAPI error (${response.status}): ${errorText}`);\n      return new Response(\n        JSON.stringify({ \n          success: false, \n          error: `ScraperAPI returned ${response.status} ${response.statusText}` \n        }),\n        { status: response.status, headers }\n      );\n    }\n    \n    // Get content from response\n    const content = await response.text();\n    \n    // Process HTML content - extract main content with improved extraction\n    const cleanedHtml = content\n      .replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, '')\n      .replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, '')\n      .replace(/<head\\b[^<]*(?:(?!<\\/head>)<[^<]*)*<\\/head>/gi, '');\n    \n    // Extract main content using a variety of selectors to increase success chances\n    // For modern docs/wikis/blogs, check more tag patterns\n    let extractedContent = '';\n    \n    // Try to find content based on common container patterns\n    // 1. Check for article/main content\n    const articleMatch = cleanedHtml.match(/<article[^>]*>([\\s\\S]*?)<\\/article>/i) ||\n                        cleanedHtml.match(/<main[^>]*>([\\s\\S]*?)<\\/main>/i);\n    \n    // 2. Check for common doc site containers like div with class=\"content\" or id=\"content\"\n    const contentDivMatch = cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*content[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                          cleanedHtml.match(/<div[^>]*id=[\"']content[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                          cleanedHtml.match(/<div[^>]*class=[\"']container[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                          cleanedHtml.match(/<div[^>]*class=[\"']main[\"'][^>]*>([\\s\\S]*?)<\\/div>/i);\n    \n    // 3. Check for documentation-specific elements like markdown containers\n    const docMatch = cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*markdown[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                   cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*docs?[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                   cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*documentation[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i);\n                     \n    // 4. Try GitHub-specific selectors\n    const githubMatch = cleanedHtml.match(/<div[^>]*class=[\"']readme[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                      cleanedHtml.match(/<article[^>]*class=[\"']markdown-body[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/article>/i);\n    \n    // Use the first successful match\n    if (articleMatch && articleMatch[1]) {\n      extractedContent = articleMatch[1];\n      console.log(\"Extracted content from article/main tag\");\n    } else if (docMatch && docMatch[1]) {\n      extractedContent = docMatch[1];\n      console.log(\"Extracted content from documentation container\");\n    } else if (githubMatch && githubMatch[1]) {\n      extractedContent = githubMatch[1];\n      console.log(\"Extracted content from GitHub-specific container\");\n    } else if (contentDivMatch && contentDivMatch[1]) {\n      extractedContent = contentDivMatch[1];\n      console.log(\"Extracted content from content div\");\n    } else {\n      // No specific container found, take the body content but remove common non-content areas\n      const bodyMatch = cleanedHtml.match(/<body[^>]*>([\\s\\S]*?)<\\/body>/i);\n      if (bodyMatch && bodyMatch[1]) {\n        let bodyContent = bodyMatch[1];\n        \n        // Remove common non-content areas\n        bodyContent = bodyContent\n          .replace(/<header[^>]*>[\\s\\S]*?<\\/header>/gi, '')\n          .replace(/<footer[^>]*>[\\s\\S]*?<\\/footer>/gi, '')\n          .replace(/<nav[^>]*>[\\s\\S]*?<\\/nav>/gi, '')\n          .replace(/<aside[^>]*>[\\s\\S]*?<\\/aside>/gi, '')\n          .replace(/<div[^>]*class=[\"'][^\"']*sidebar[^\"']*[\"'][^>]*>[\\s\\S]*?<\\/div>/gi, '')\n          .replace(/<div[^>]*class=[\"'][^\"']*menu[^\"']*[\"'][^>]*>[\\s\\S]*?<\\/div>/gi, '')\n          .replace(/<div[^>]*class=[\"'][^\"']*navigation[^\"']*[\"'][^>]*>[\\s\\S]*?<\\/div>/gi, '');\n        \n        extractedContent = bodyContent;\n        console.log(\"Falling back to filtered body content\");\n      } else {\n        // Last resort: just use the entire HTML with scripts/styles removed\n        extractedContent = cleanedHtml;\n        console.log(\"Using entire page content as fallback\");\n      }\n    }\n    \n    // Clean up the extracted content - convert to readable text\n    // First remove all images, forms, and iframes to reduce noise\n    extractedContent = extractedContent\n      .replace(/<img[^>]*>/gi, '[IMAGE]')\n      .replace(/<form[^>]*>[\\s\\S]*?<\\/form>/gi, '')\n      .replace(/<iframe[^>]*>[\\s\\S]*?<\\/iframe>/gi, '')\n      .replace(/<svg[^>]*>[\\s\\S]*?<\\/svg>/gi, '');\n    \n    // Then extract text from the remaining HTML\n    const textContent = extractedContent\n      .replace(/<h1[^>]*>([\\s\\S]*?)<\\/h1>/gi, '# $1\\n\\n')\n      .replace(/<h2[^>]*>([\\s\\S]*?)<\\/h2>/gi, '## $1\\n\\n')\n      .replace(/<h3[^>]*>([\\s\\S]*?)<\\/h3>/gi, '### $1\\n\\n')\n      .replace(/<h4[^>]*>([\\s\\S]*?)<\\/h4>/gi, '#### $1\\n\\n')\n      .replace(/<h5[^>]*>([\\s\\S]*?)<\\/h5>/gi, '##### $1\\n\\n')\n      .replace(/<h6[^>]*>([\\s\\S]*?)<\\/h6>/gi, '###### $1\\n\\n')\n      .replace(/<p[^>]*>([\\s\\S]*?)<\\/p>/gi, '$1\\n\\n')\n      .replace(/<br\\s*\\/?>/gi, '\\n')\n      .replace(/<li[^>]*>([\\s\\S]*?)<\\/li>/gi, '\u2022 $1\\n')\n      .replace(/<a[^>]*href=[\"']([\\s\\S]*?)[\"'][^>]*>([\\s\\S]*?)<\\/a>/gi, '[$2]($1)')\n      .replace(/<[^>]*>/g, '') // Remove any remaining HTML tags\n      .replace(/\\n\\s*\\n/g, '\\n\\n') // Remove excessive newlines\n      .replace(/&nbsp;/g, ' ')\n      .replace(/&lt;/g, '<')\n      .replace(/&gt;/g, '>')\n      .replace(/&amp;/g, '&')\n      .replace(/&quot;/g, '\"')\n      .trim();\n    \n    // Only return if we got something substantial (more than just a few characters)\n    const MIN_CONTENT_LENGTH = 100; // Minimum characters to consider content valid\n    const processedContent = textContent.length > MIN_CONTENT_LENGTH ? textContent : cleanedHtml;\n    \n    // Return processed content\n    return new Response(\n      JSON.stringify({\n        success: true,\n        content: processedContent,\n        service: 'scraperapi',\n        raw: content.substring(0, 500) + (content.length > 500 ? '...' : '') // Include first 500 chars of raw response for debugging\n      }),\n      { headers }\n    );\n  } catch (error) {\n    console.error('ScraperAPI scraping error:', error);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message || 'Unknown error during ScraperAPI scraping' \n      }),\n      { status: 500, headers }\n    );\n  }\n}\n\n// Helper function to extract main content from HTML\nfunction extractMainContent(html) {\n  try {\n    // Simple content extraction - look for article, main, or content divs\n    const mainContentRegexes = [\n      /<article[^>]*>([\\s\\S]*?)<\\/article>/i,\n      /<main[^>]*>([\\s\\S]*?)<\\/main>/i,\n      /<div[^>]*id=[\"']?content[\"']?[^>]*>([\\s\\S]*?)<\\/div>/i,\n      /<div[^>]*class=[\"']?content[\"']?[^>]*>([\\s\\S]*?)<\\/div>/i,\n      /<div[^>]*class=[\"']?main[\"']?[^>]*>([\\s\\S]*?)<\\/div>/i,\n      /<div[^>]*id=[\"']?main[\"']?[^>]*>([\\s\\S]*?)<\\/div>/i\n    ];\n    \n    for (const regex of mainContentRegexes) {\n      const match = html.match(regex);\n      if (match && match[1] && match[1].length > 200) {\n        // Found substantive main content\n        return match[1]\n          .replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, '')\n          .replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, '')\n          .replace(/<[^>]*>/g, '');\n      }\n    }\n    \n    // No main content found, return cleaned HTML\n    return html.replace(/<[^>]*>/g, '');\n  } catch (error) {\n    console.error('Error extracting main content:', error);\n    return html.replace(/<[^>]*>/g, '');\n  }\n} ", "export async function onRequest(context) {\n  // CORS headers\n  const headers = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n    'Content-Type': 'application/json'\n  };\n\n  // Handle preflight OPTIONS request\n  if (context.request.method === 'OPTIONS') {\n    return new Response(null, { headers });\n  }\n\n  try {\n    if (context.request.method !== 'POST') {\n      return new Response(\n        JSON.stringify({ success: false, error: 'Method not allowed' }),\n        { status: 405, headers }\n      );\n    }\n\n    // Get URL and options from request body\n    const body = await context.request.json();\n    const { url, renderJs } = body;\n\n    if (!url) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'URL is required' }),\n        { status: 400, headers }\n      );\n    }\n\n    console.log(`ScrapingAnt scraping: ${url}`);\n\n    // Get API key from environment\n    const apiKey = context.env.SCRAPINGANT_API_KEY;\n    if (!apiKey) {\n      return new Response(\n        JSON.stringify({ success: false, error: 'ScrapingAnt API key not configured' }),\n        { status: 500, headers }\n      );\n    }\n\n    // Make a GET request to ScrapingAnt API\n    console.log(`Calling ScrapingAnt API for ${url}`);\n    \n    const response = await fetch(`https://api.scrapingant.com/v2/general?url=${encodeURIComponent(url)}&browser=${renderJs ? 'true' : 'false'}`, {\n      method: 'GET',\n      headers: {\n        'x-api-key': apiKey\n      }\n    });\n    \n    if (!response.ok) {\n      const errorText = await response.text();\n      console.error(`ScrapingAnt API error (${response.status}): ${errorText}`);\n      return new Response(\n        JSON.stringify({ \n          success: false, \n          error: `ScrapingAnt API returned ${response.status} ${response.statusText}` \n        }),\n        { status: response.status, headers }\n      );\n    }\n    \n    // Get content from response\n    const content = await response.text();\n    \n    // Process HTML content - extract main content with improved extraction\n    const cleanedHtml = content\n      .replace(/<script\\b[^<]*(?:(?!<\\/script>)<[^<]*)*<\\/script>/gi, '')\n      .replace(/<style\\b[^<]*(?:(?!<\\/style>)<[^<]*)*<\\/style>/gi, '')\n      .replace(/<head\\b[^<]*(?:(?!<\\/head>)<[^<]*)*<\\/head>/gi, '');\n    \n    // Extract main content using a variety of selectors to increase success chances\n    // For modern docs/wikis/blogs, check more tag patterns\n    let extractedContent = '';\n    \n    // Try to find content based on common container patterns\n    // 1. Check for article/main content\n    const articleMatch = cleanedHtml.match(/<article[^>]*>([\\s\\S]*?)<\\/article>/i) ||\n                        cleanedHtml.match(/<main[^>]*>([\\s\\S]*?)<\\/main>/i);\n    \n    // 2. Check for common doc site containers like div with class=\"content\" or id=\"content\"\n    const contentDivMatch = cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*content[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                          cleanedHtml.match(/<div[^>]*id=[\"']content[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                          cleanedHtml.match(/<div[^>]*class=[\"']container[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                          cleanedHtml.match(/<div[^>]*class=[\"']main[\"'][^>]*>([\\s\\S]*?)<\\/div>/i);\n    \n    // 3. Check for documentation-specific elements like markdown containers\n    const docMatch = cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*markdown[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                   cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*docs?[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                   cleanedHtml.match(/<div[^>]*class=[\"'][^\"']*documentation[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i);\n                     \n    // 4. Try GitHub-specific selectors\n    const githubMatch = cleanedHtml.match(/<div[^>]*class=[\"']readme[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/div>/i) ||\n                      cleanedHtml.match(/<article[^>]*class=[\"']markdown-body[^\"']*[\"'][^>]*>([\\s\\S]*?)<\\/article>/i);\n    \n    // Use the first successful match\n    if (articleMatch && articleMatch[1]) {\n      extractedContent = articleMatch[1];\n      console.log(\"Extracted content from article/main tag\");\n    } else if (docMatch && docMatch[1]) {\n      extractedContent = docMatch[1];\n      console.log(\"Extracted content from documentation container\");\n    } else if (githubMatch && githubMatch[1]) {\n      extractedContent = githubMatch[1];\n      console.log(\"Extracted content from GitHub-specific container\");\n    } else if (contentDivMatch && contentDivMatch[1]) {\n      extractedContent = contentDivMatch[1];\n      console.log(\"Extracted content from content div\");\n    } else {\n      // No specific container found, take the body content but remove common non-content areas\n      const bodyMatch = cleanedHtml.match(/<body[^>]*>([\\s\\S]*?)<\\/body>/i);\n      if (bodyMatch && bodyMatch[1]) {\n        let bodyContent = bodyMatch[1];\n        \n        // Remove common non-content areas\n        bodyContent = bodyContent\n          .replace(/<header[^>]*>[\\s\\S]*?<\\/header>/gi, '')\n          .replace(/<footer[^>]*>[\\s\\S]*?<\\/footer>/gi, '')\n          .replace(/<nav[^>]*>[\\s\\S]*?<\\/nav>/gi, '')\n          .replace(/<aside[^>]*>[\\s\\S]*?<\\/aside>/gi, '')\n          .replace(/<div[^>]*class=[\"'][^\"']*sidebar[^\"']*[\"'][^>]*>[\\s\\S]*?<\\/div>/gi, '')\n          .replace(/<div[^>]*class=[\"'][^\"']*menu[^\"']*[\"'][^>]*>[\\s\\S]*?<\\/div>/gi, '')\n          .replace(/<div[^>]*class=[\"'][^\"']*navigation[^\"']*[\"'][^>]*>[\\s\\S]*?<\\/div>/gi, '');\n        \n        extractedContent = bodyContent;\n        console.log(\"Falling back to filtered body content\");\n      } else {\n        // Last resort: just use the entire HTML with scripts/styles removed\n        extractedContent = cleanedHtml;\n        console.log(\"Using entire page content as fallback\");\n      }\n    }\n    \n    // Clean up the extracted content - convert to readable text\n    // First remove all images, forms, and iframes to reduce noise\n    extractedContent = extractedContent\n      .replace(/<img[^>]*>/gi, '[IMAGE]')\n      .replace(/<form[^>]*>[\\s\\S]*?<\\/form>/gi, '')\n      .replace(/<iframe[^>]*>[\\s\\S]*?<\\/iframe>/gi, '')\n      .replace(/<svg[^>]*>[\\s\\S]*?<\\/svg>/gi, '');\n    \n    // Then extract text from the remaining HTML\n    const textContent = extractedContent\n      .replace(/<h1[^>]*>([\\s\\S]*?)<\\/h1>/gi, '# $1\\n\\n')\n      .replace(/<h2[^>]*>([\\s\\S]*?)<\\/h2>/gi, '## $1\\n\\n')\n      .replace(/<h3[^>]*>([\\s\\S]*?)<\\/h3>/gi, '### $1\\n\\n')\n      .replace(/<h4[^>]*>([\\s\\S]*?)<\\/h4>/gi, '#### $1\\n\\n')\n      .replace(/<h5[^>]*>([\\s\\S]*?)<\\/h5>/gi, '##### $1\\n\\n')\n      .replace(/<h6[^>]*>([\\s\\S]*?)<\\/h6>/gi, '###### $1\\n\\n')\n      .replace(/<p[^>]*>([\\s\\S]*?)<\\/p>/gi, '$1\\n\\n')\n      .replace(/<br\\s*\\/?>/gi, '\\n')\n      .replace(/<li[^>]*>([\\s\\S]*?)<\\/li>/gi, '\u2022 $1\\n')\n      .replace(/<a[^>]*href=[\"']([\\s\\S]*?)[\"'][^>]*>([\\s\\S]*?)<\\/a>/gi, '[$2]($1)')\n      .replace(/<[^>]*>/g, '') // Remove any remaining HTML tags\n      .replace(/\\n\\s*\\n/g, '\\n\\n') // Remove excessive newlines\n      .replace(/&nbsp;/g, ' ')\n      .replace(/&lt;/g, '<')\n      .replace(/&gt;/g, '>')\n      .replace(/&amp;/g, '&')\n      .replace(/&quot;/g, '\"')\n      .trim();\n    \n    // Only return if we got something substantial (more than just a few characters)\n    const MIN_CONTENT_LENGTH = 100; // Minimum characters to consider content valid\n    const processedContent = textContent.length > MIN_CONTENT_LENGTH ? textContent : cleanedHtml;\n    \n    // Return processed content\n    return new Response(\n      JSON.stringify({\n        success: true,\n        content: processedContent,\n        service: 'scrapingant',\n        raw: content.substring(0, 500) + (content.length > 500 ? '...' : '') // Include first 500 chars of raw response for debugging\n      }),\n      { headers }\n    );\n  } catch (error) {\n    console.error('ScrapingAnt scraping error:', error);\n    \n    return new Response(\n      JSON.stringify({ \n        success: false, \n        error: error.message || 'Unknown error during ScrapingAnt scraping' \n      }),\n      { status: 500, headers }\n    );\n  }\n} ", "export async function onRequest(context) {\n  // Make sure OPTIONS requests are handled properly\n  if (context.request.method === \"OPTIONS\") {\n    return new Response(null, {\n      headers: {\n        \"Access-Control-Allow-Origin\": \"*\",\n        \"Access-Control-Allow-Methods\": \"GET, POST, PUT, DELETE, OPTIONS\",\n        \"Access-Control-Allow-Headers\": \"Content-Type, Authorization\",\n        \"Access-Control-Max-Age\": \"86400\",\n      },\n    });\n  }\n\n  // Continue to the next handler\n  return context.next();\n} ", "import { onRequestPost as __api_enhance_js_onRequestPost } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/enhance.js\"\nimport { onRequestPost as __api_pollinations_text_js_onRequestPost } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/pollinations-text.js\"\nimport { onRequestPost as __api_scrape_url_js_onRequestPost } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/scrape-url.js\"\nimport { onRequestOptions as __api_speech_to_text_js_onRequestOptions } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/speech-to-text.js\"\nimport { onRequestPost as __api_speech_to_text_js_onRequestPost } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/speech-to-text.js\"\nimport { onRequest as __api_firecrawl_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/firecrawl.js\"\nimport { onRequest as __api_multi_scrape_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/multi-scrape.js\"\nimport { onRequest as __api_phantom_scrape_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/phantom-scrape.js\"\nimport { onRequest as __api_pollinations_search_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/pollinations-search.js\"\nimport { onRequest as __api_scraperapi_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/scraperapi.js\"\nimport { onRequest as __api_scrapingant_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/api/scrapingant.js\"\nimport { onRequest as ___middleware_js_onRequest } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/functions/_middleware.js\"\n\nexport const routes = [\n    {\n      routePath: \"/api/enhance\",\n      mountPath: \"/api\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__api_enhance_js_onRequestPost],\n    },\n  {\n      routePath: \"/api/pollinations-text\",\n      mountPath: \"/api\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__api_pollinations_text_js_onRequestPost],\n    },\n  {\n      routePath: \"/api/scrape-url\",\n      mountPath: \"/api\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__api_scrape_url_js_onRequestPost],\n    },\n  {\n      routePath: \"/api/speech-to-text\",\n      mountPath: \"/api\",\n      method: \"OPTIONS\",\n      middlewares: [],\n      modules: [__api_speech_to_text_js_onRequestOptions],\n    },\n  {\n      routePath: \"/api/speech-to-text\",\n      mountPath: \"/api\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__api_speech_to_text_js_onRequestPost],\n    },\n  {\n      routePath: \"/api/firecrawl\",\n      mountPath: \"/api\",\n      method: \"\",\n      middlewares: [],\n      modules: [__api_firecrawl_js_onRequest],\n    },\n  {\n      routePath: \"/api/multi-scrape\",\n      mountPath: \"/api\",\n      method: \"\",\n      middlewares: [],\n      modules: [__api_multi_scrape_js_onRequest],\n    },\n  {\n      routePath: \"/api/phantom-scrape\",\n      mountPath: \"/api\",\n      method: \"\",\n      middlewares: [],\n      modules: [__api_phantom_scrape_js_onRequest],\n    },\n  {\n      routePath: \"/api/pollinations-search\",\n      mountPath: \"/api\",\n      method: \"\",\n      middlewares: [],\n      modules: [__api_pollinations_search_js_onRequest],\n    },\n  {\n      routePath: \"/api/scraperapi\",\n      mountPath: \"/api\",\n      method: \"\",\n      middlewares: [],\n      modules: [__api_scraperapi_js_onRequest],\n    },\n  {\n      routePath: \"/api/scrapingant\",\n      mountPath: \"/api\",\n      method: \"\",\n      middlewares: [],\n      modules: [__api_scrapingant_js_onRequest],\n    },\n  {\n      routePath: \"/\",\n      mountPath: \"/\",\n      method: \"\",\n      middlewares: [___middleware_js_onRequest],\n      modules: [],\n    },\n  ]", "/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type:\n    | \"OPEN\"\n    | \"CLOSE\"\n    | \"PATTERN\"\n    | \"NAME\"\n    | \"CHAR\"\n    | \"ESCAPED_CHAR\"\n    | \"MODIFIER\"\n    | \"END\";\n  index: number;\n  value: string;\n}\n\n/**\n * Tokenize input string.\n */\nfunction lexer(str: string): LexToken[] {\n  const tokens: LexToken[] = [];\n  let i = 0;\n\n  while (i < str.length) {\n    const char = str[i];\n\n    if (char === \"*\" || char === \"+\" || char === \"?\") {\n      tokens.push({ type: \"MODIFIER\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"\\\\\") {\n      tokens.push({ type: \"ESCAPED_CHAR\", index: i++, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"{\") {\n      tokens.push({ type: \"OPEN\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"}\") {\n      tokens.push({ type: \"CLOSE\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \":\") {\n      let name = \"\";\n      let j = i + 1;\n\n      while (j < str.length) {\n        const code = str.charCodeAt(j);\n\n        if (\n          // `0-9`\n          (code >= 48 && code <= 57) ||\n          // `A-Z`\n          (code >= 65 && code <= 90) ||\n          // `a-z`\n          (code >= 97 && code <= 122) ||\n          // `_`\n          code === 95\n        ) {\n          name += str[j++];\n          continue;\n        }\n\n        break;\n      }\n\n      if (!name) throw new TypeError(`Missing parameter name at ${i}`);\n\n      tokens.push({ type: \"NAME\", index: i, value: name });\n      i = j;\n      continue;\n    }\n\n    if (char === \"(\") {\n      let count = 1;\n      let pattern = \"\";\n      let j = i + 1;\n\n      if (str[j] === \"?\") {\n        throw new TypeError(`Pattern cannot start with \"?\" at ${j}`);\n      }\n\n      while (j < str.length) {\n        if (str[j] === \"\\\\\") {\n          pattern += str[j++] + str[j++];\n          continue;\n        }\n\n        if (str[j] === \")\") {\n          count--;\n          if (count === 0) {\n            j++;\n            break;\n          }\n        } else if (str[j] === \"(\") {\n          count++;\n          if (str[j + 1] !== \"?\") {\n            throw new TypeError(`Capturing groups are not allowed at ${j}`);\n          }\n        }\n\n        pattern += str[j++];\n      }\n\n      if (count) throw new TypeError(`Unbalanced pattern at ${i}`);\n      if (!pattern) throw new TypeError(`Missing pattern at ${i}`);\n\n      tokens.push({ type: \"PATTERN\", index: i, value: pattern });\n      i = j;\n      continue;\n    }\n\n    tokens.push({ type: \"CHAR\", index: i, value: str[i++] });\n  }\n\n  tokens.push({ type: \"END\", index: i, value: \"\" });\n\n  return tokens;\n}\n\nexport interface ParseOptions {\n  /**\n   * Set the default delimiter for repeat parameters. (default: `'/'`)\n   */\n  delimiter?: string;\n  /**\n   * List of characters to automatically consider prefixes when parsing.\n   */\n  prefixes?: string;\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): Token[] {\n  const tokens = lexer(str);\n  const { prefixes = \"./\", delimiter = \"/#?\" } = options;\n  const result: Token[] = [];\n  let key = 0;\n  let i = 0;\n  let path = \"\";\n\n  const tryConsume = (type: LexToken[\"type\"]): string | undefined => {\n    if (i < tokens.length && tokens[i].type === type) return tokens[i++].value;\n  };\n\n  const mustConsume = (type: LexToken[\"type\"]): string => {\n    const value = tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = tokens[i];\n    throw new TypeError(`Unexpected ${nextType} at ${index}, expected ${type}`);\n  };\n\n  const consumeText = (): string => {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = tryConsume(\"CHAR\") || tryConsume(\"ESCAPED_CHAR\"))) {\n      result += value;\n    }\n    return result;\n  };\n\n  const isSafe = (value: string): boolean => {\n    for (const char of delimiter) if (value.indexOf(char) > -1) return true;\n    return false;\n  };\n\n  const safePattern = (prefix: string) => {\n    const prev = result[result.length - 1];\n    const prevText = prefix || (prev && typeof prev === \"string\" ? prev : \"\");\n\n    if (prev && !prevText) {\n      throw new TypeError(\n        `Must have text between two parameters, missing text after \"${(prev as Key).name}\"`,\n      );\n    }\n\n    if (!prevText || isSafe(prevText)) return `[^${escapeString(delimiter)}]+?`;\n    return `(?:(?!${escapeString(prevText)})[^${escapeString(delimiter)}])+?`;\n  };\n\n  while (i < tokens.length) {\n    const char = tryConsume(\"CHAR\");\n    const name = tryConsume(\"NAME\");\n    const pattern = tryConsume(\"PATTERN\");\n\n    if (name || pattern) {\n      let prefix = char || \"\";\n\n      if (prefixes.indexOf(prefix) === -1) {\n        path += prefix;\n        prefix = \"\";\n      }\n\n      if (path) {\n        result.push(path);\n        path = \"\";\n      }\n\n      result.push({\n        name: name || key++,\n        prefix,\n        suffix: \"\",\n        pattern: pattern || safePattern(prefix),\n        modifier: tryConsume(\"MODIFIER\") || \"\",\n      });\n      continue;\n    }\n\n    const value = char || tryConsume(\"ESCAPED_CHAR\");\n    if (value) {\n      path += value;\n      continue;\n    }\n\n    if (path) {\n      result.push(path);\n      path = \"\";\n    }\n\n    const open = tryConsume(\"OPEN\");\n    if (open) {\n      const prefix = consumeText();\n      const name = tryConsume(\"NAME\") || \"\";\n      const pattern = tryConsume(\"PATTERN\") || \"\";\n      const suffix = consumeText();\n\n      mustConsume(\"CLOSE\");\n\n      result.push({\n        name: name || (pattern ? key++ : \"\"),\n        pattern: name && !pattern ? safePattern(prefix) : pattern,\n        prefix,\n        suffix,\n        modifier: tryConsume(\"MODIFIER\") || \"\",\n      });\n      continue;\n    }\n\n    mustConsume(\"END\");\n  }\n\n  return result;\n}\n\nexport interface TokensToFunctionOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Function for encoding input strings for output.\n   */\n  encode?: (value: string, token: Key) => string;\n  /**\n   * When `false` the function can produce an invalid (unmatched) path. (default: `true`)\n   */\n  validate?: boolean;\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends object = object>(\n  str: string,\n  options?: ParseOptions & TokensToFunctionOptions,\n) {\n  return tokensToFunction<P>(parse(str, options), options);\n}\n\nexport type PathFunction<P extends object = object> = (data?: P) => string;\n\n/**\n * Expose a method for transforming tokens into the path function.\n */\nexport function tokensToFunction<P extends object = object>(\n  tokens: Token[],\n  options: TokensToFunctionOptions = {},\n): PathFunction<P> {\n  const reFlags = flags(options);\n  const { encode = (x: string) => x, validate = true } = options;\n\n  // Compile all the tokens into regexps.\n  const matches = tokens.map((token) => {\n    if (typeof token === \"object\") {\n      return new RegExp(`^(?:${token.pattern})$`, reFlags);\n    }\n  });\n\n  return (data: Record<string, any> | null | undefined) => {\n    let path = \"\";\n\n    for (let i = 0; i < tokens.length; i++) {\n      const token = tokens[i];\n\n      if (typeof token === \"string\") {\n        path += token;\n        continue;\n      }\n\n      const value = data ? data[token.name] : undefined;\n      const optional = token.modifier === \"?\" || token.modifier === \"*\";\n      const repeat = token.modifier === \"*\" || token.modifier === \"+\";\n\n      if (Array.isArray(value)) {\n        if (!repeat) {\n          throw new TypeError(\n            `Expected \"${token.name}\" to not repeat, but got an array`,\n          );\n        }\n\n        if (value.length === 0) {\n          if (optional) continue;\n\n          throw new TypeError(`Expected \"${token.name}\" to not be empty`);\n        }\n\n        for (let j = 0; j < value.length; j++) {\n          const segment = encode(value[j], token);\n\n          if (validate && !(matches[i] as RegExp).test(segment)) {\n            throw new TypeError(\n              `Expected all \"${token.name}\" to match \"${token.pattern}\", but got \"${segment}\"`,\n            );\n          }\n\n          path += token.prefix + segment + token.suffix;\n        }\n\n        continue;\n      }\n\n      if (typeof value === \"string\" || typeof value === \"number\") {\n        const segment = encode(String(value), token);\n\n        if (validate && !(matches[i] as RegExp).test(segment)) {\n          throw new TypeError(\n            `Expected \"${token.name}\" to match \"${token.pattern}\", but got \"${segment}\"`,\n          );\n        }\n\n        path += token.prefix + segment + token.suffix;\n        continue;\n      }\n\n      if (optional) continue;\n\n      const typeOfMessage = repeat ? \"an array\" : \"a string\";\n      throw new TypeError(`Expected \"${token.name}\" to be ${typeOfMessage}`);\n    }\n\n    return path;\n  };\n}\n\nexport interface RegexpToFunctionOptions {\n  /**\n   * Function for decoding strings for params.\n   */\n  decode?: (value: string, token: Key) => string;\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends object = object> {\n  path: string;\n  index: number;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends object = object> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends object = object> = (\n  path: string,\n) => Match<P>;\n\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nexport function match<P extends object = object>(\n  str: Path,\n  options?: ParseOptions & TokensToRegexpOptions & RegexpToFunctionOptions,\n) {\n  const keys: Key[] = [];\n  const re = pathToRegexp(str, keys, options);\n  return regexpToFunction<P>(re, keys, options);\n}\n\n/**\n * Create a path match function from `path-to-regexp` output.\n */\nexport function regexpToFunction<P extends object = object>(\n  re: RegExp,\n  keys: Key[],\n  options: RegexpToFunctionOptions = {},\n): MatchFunction<P> {\n  const { decode = (x: string) => x } = options;\n\n  return function (pathname: string) {\n    const m = re.exec(pathname);\n    if (!m) return false;\n\n    const { 0: path, index } = m;\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n\n      if (key.modifier === \"*\" || key.modifier === \"+\") {\n        params[key.name] = m[i].split(key.prefix + key.suffix).map((value) => {\n          return decode(value, key);\n        });\n      } else {\n        params[key.name] = decode(m[i], key);\n      }\n    }\n\n    return { path, index, params };\n  };\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escapeString(str: string) {\n  return str.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g, \"\\\\$1\");\n}\n\n/**\n * Get the flags for a regexp from the options.\n */\nfunction flags(options?: { sensitive?: boolean }) {\n  return options && options.sensitive ? \"\" : \"i\";\n}\n\n/**\n * Metadata about a key.\n */\nexport interface Key {\n  name: string | number;\n  prefix: string;\n  suffix: string;\n  pattern: string;\n  modifier: string;\n}\n\n/**\n * A token is a string (nothing special) or key metadata (capture group).\n */\nexport type Token = string | Key;\n\n/**\n * Pull out keys from a regexp.\n */\nfunction regexpToRegexp(path: RegExp, keys?: Key[]): RegExp {\n  if (!keys) return path;\n\n  const groupsRegex = /\\((?:\\?<(.*?)>)?(?!\\?)/g;\n\n  let index = 0;\n  let execResult = groupsRegex.exec(path.source);\n  while (execResult) {\n    keys.push({\n      // Use parenthesized substring match if available, index otherwise\n      name: execResult[1] || index++,\n      prefix: \"\",\n      suffix: \"\",\n      modifier: \"\",\n      pattern: \"\",\n    });\n    execResult = groupsRegex.exec(path.source);\n  }\n\n  return path;\n}\n\n/**\n * Transform an array into a regexp.\n */\nfunction arrayToRegexp(\n  paths: Array<string | RegExp>,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n): RegExp {\n  const parts = paths.map((path) => pathToRegexp(path, keys, options).source);\n  return new RegExp(`(?:${parts.join(\"|\")})`, flags(options));\n}\n\n/**\n * Create a path regexp from string input.\n */\nfunction stringToRegexp(\n  path: string,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n) {\n  return tokensToRegexp(parse(path, options), keys, options);\n}\n\nexport interface TokensToRegexpOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * When `true` the regexp won't allow an optional trailing delimiter to match. (default: `false`)\n   */\n  strict?: boolean;\n  /**\n   * When `true` the regexp will match to the end of the string. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * When `true` the regexp will match from the beginning of the string. (default: `true`)\n   */\n  start?: boolean;\n  /**\n   * Sets the final character for non-ending optimistic matches. (default: `/`)\n   */\n  delimiter?: string;\n  /**\n   * List of characters that can also be \"end\" characters.\n   */\n  endsWith?: string;\n  /**\n   * Encode path tokens for use in the `RegExp`.\n   */\n  encode?: (value: string) => string;\n}\n\n/**\n * Expose a function for taking tokens and returning a RegExp.\n */\nexport function tokensToRegexp(\n  tokens: Token[],\n  keys?: Key[],\n  options: TokensToRegexpOptions = {},\n) {\n  const {\n    strict = false,\n    start = true,\n    end = true,\n    encode = (x: string) => x,\n    delimiter = \"/#?\",\n    endsWith = \"\",\n  } = options;\n  const endsWithRe = `[${escapeString(endsWith)}]|$`;\n  const delimiterRe = `[${escapeString(delimiter)}]`;\n  let route = start ? \"^\" : \"\";\n\n  // Iterate over the tokens and create our regexp string.\n  for (const token of tokens) {\n    if (typeof token === \"string\") {\n      route += escapeString(encode(token));\n    } else {\n      const prefix = escapeString(encode(token.prefix));\n      const suffix = escapeString(encode(token.suffix));\n\n      if (token.pattern) {\n        if (keys) keys.push(token);\n\n        if (prefix || suffix) {\n          if (token.modifier === \"+\" || token.modifier === \"*\") {\n            const mod = token.modifier === \"*\" ? \"?\" : \"\";\n            route += `(?:${prefix}((?:${token.pattern})(?:${suffix}${prefix}(?:${token.pattern}))*)${suffix})${mod}`;\n          } else {\n            route += `(?:${prefix}(${token.pattern})${suffix})${token.modifier}`;\n          }\n        } else {\n          if (token.modifier === \"+\" || token.modifier === \"*\") {\n            throw new TypeError(\n              `Can not repeat \"${token.name}\" without a prefix and suffix`,\n            );\n          }\n\n          route += `(${token.pattern})${token.modifier}`;\n        }\n      } else {\n        route += `(?:${prefix}${suffix})${token.modifier}`;\n      }\n    }\n  }\n\n  if (end) {\n    if (!strict) route += `${delimiterRe}?`;\n\n    route += !options.endsWith ? \"$\" : `(?=${endsWithRe})`;\n  } else {\n    const endToken = tokens[tokens.length - 1];\n    const isEndDelimited =\n      typeof endToken === \"string\"\n        ? delimiterRe.indexOf(endToken[endToken.length - 1]) > -1\n        : endToken === undefined;\n\n    if (!strict) {\n      route += `(?:${delimiterRe}(?=${endsWithRe}))?`;\n    }\n\n    if (!isEndDelimited) {\n      route += `(?=${delimiterRe}|${endsWithRe})`;\n    }\n  }\n\n  return new RegExp(route, flags(options));\n}\n\n/**\n * Supported `path-to-regexp` input types.\n */\nexport type Path = string | RegExp | Array<string | RegExp>;\n\n/**\n * Normalize the given path string, returning a regular expression.\n *\n * An empty array can be passed in for the keys, which will hold the\n * placeholder key descriptions. For example, using `/user/:id`, `keys` will\n * contain `[{ name: 'id', delimiter: '/', optional: false, repeat: false }]`.\n */\nexport function pathToRegexp(\n  path: Path,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n) {\n  if (path instanceof RegExp) return regexpToRegexp(path, keys);\n  if (Array.isArray(path)) return arrayToRegexp(path, keys, options);\n  return stringToRegexp(path, keys, options);\n}\n", "import { match } from \"path-to-regexp\";\n\n//note: this explicitly does not include the * character, as pages requires this\nconst escapeRegex = /[.+?^${}()|[\\]\\\\]/g;\n\ntype HTTPMethod =\n\t| \"HEAD\"\n\t| \"OPTIONS\"\n\t| \"GET\"\n\t| \"POST\"\n\t| \"PUT\"\n\t| \"PATCH\"\n\t| \"DELETE\";\n\n/* TODO: Grab these from @cloudflare/workers-types instead */\ntype Params<P extends string = string> = Record<P, string | string[]>;\n\ntype EventContext<Env, P extends string, Data> = {\n\trequest: Request;\n\tfunctionPath: string;\n\twaitUntil: (promise: Promise<unknown>) => void;\n\tpassThroughOnException: () => void;\n\tnext: (input?: Request | string, init?: RequestInit) => Promise<Response>;\n\tenv: Env & { ASSETS: { fetch: typeof fetch } };\n\tparams: Params<P>;\n\tdata: Data;\n};\n\ndeclare type PagesFunction<\n\tEnv = unknown,\n\tP extends string = string,\n\tData extends Record<string, unknown> = Record<string, unknown>,\n> = (context: EventContext<Env, P, Data>) => Response | Promise<Response>;\n/* end @cloudflare/workers-types */\n\ntype RouteHandler = {\n\troutePath: string;\n\tmountPath: string;\n\tmethod?: HTTPMethod;\n\tmodules: PagesFunction[];\n\tmiddlewares: PagesFunction[];\n};\n\n// inject `routes` via ESBuild\ndeclare const routes: RouteHandler[];\n// define `__FALLBACK_SERVICE__` via ESBuild\ndeclare const __FALLBACK_SERVICE__: string;\n\n// expect an ASSETS fetcher binding pointing to the asset-server stage\ntype FetchEnv = {\n\t[name: string]: { fetch: typeof fetch };\n\tASSETS: { fetch: typeof fetch };\n};\n\ntype WorkerContext = {\n\twaitUntil: (promise: Promise<unknown>) => void;\n\tpassThroughOnException: () => void;\n};\n\nfunction* executeRequest(request: Request) {\n\tconst requestPath = new URL(request.url).pathname;\n\n\t// First, iterate through the routes (backwards) and execute \"middlewares\" on partial route matches\n\tfor (const route of [...routes].reverse()) {\n\t\tif (route.method && route.method !== request.method) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// replaces with \"\\\\$&\", this prepends a backslash to the matched string, e.g. \"[\" becomes \"\\[\"\n\t\tconst routeMatcher = match(route.routePath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst mountMatcher = match(route.mountPath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst matchResult = routeMatcher(requestPath);\n\t\tconst mountMatchResult = mountMatcher(requestPath);\n\t\tif (matchResult && mountMatchResult) {\n\t\t\tfor (const handler of route.middlewares.flat()) {\n\t\t\t\tyield {\n\t\t\t\t\thandler,\n\t\t\t\t\tparams: matchResult.params as Params,\n\t\t\t\t\tpath: mountMatchResult.path,\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\t// Then look for the first exact route match and execute its \"modules\"\n\tfor (const route of routes) {\n\t\tif (route.method && route.method !== request.method) {\n\t\t\tcontinue;\n\t\t}\n\t\tconst routeMatcher = match(route.routePath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: true,\n\t\t});\n\t\tconst mountMatcher = match(route.mountPath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst matchResult = routeMatcher(requestPath);\n\t\tconst mountMatchResult = mountMatcher(requestPath);\n\t\tif (matchResult && mountMatchResult && route.modules.length) {\n\t\t\tfor (const handler of route.modules.flat()) {\n\t\t\t\tyield {\n\t\t\t\t\thandler,\n\t\t\t\t\tparams: matchResult.params as Params,\n\t\t\t\t\tpath: matchResult.path,\n\t\t\t\t};\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nexport default {\n\tasync fetch(\n\t\toriginalRequest: Request,\n\t\tenv: FetchEnv,\n\t\tworkerContext: WorkerContext\n\t) {\n\t\tlet request = originalRequest;\n\t\tconst handlerIterator = executeRequest(request);\n\t\tlet data = {}; // arbitrary data the user can set between functions\n\t\tlet isFailOpen = false;\n\n\t\tconst next = async (input?: RequestInfo, init?: RequestInit) => {\n\t\t\tif (input !== undefined) {\n\t\t\t\tlet url = input;\n\t\t\t\tif (typeof input === \"string\") {\n\t\t\t\t\turl = new URL(input, request.url).toString();\n\t\t\t\t}\n\t\t\t\trequest = new Request(url, init);\n\t\t\t}\n\n\t\t\tconst result = handlerIterator.next();\n\t\t\t// Note we can't use `!result.done` because this doesn't narrow to the correct type\n\t\t\tif (result.done === false) {\n\t\t\t\tconst { handler, params, path } = result.value;\n\t\t\t\tconst context = {\n\t\t\t\t\trequest: new Request(request.clone()),\n\t\t\t\t\tfunctionPath: path,\n\t\t\t\t\tnext,\n\t\t\t\t\tparams,\n\t\t\t\t\tget data() {\n\t\t\t\t\t\treturn data;\n\t\t\t\t\t},\n\t\t\t\t\tset data(value) {\n\t\t\t\t\t\tif (typeof value !== \"object\" || value === null) {\n\t\t\t\t\t\t\tthrow new Error(\"context.data must be an object\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// user has overriden context.data, so we need to merge it with the existing data\n\t\t\t\t\t\tdata = value;\n\t\t\t\t\t},\n\t\t\t\t\tenv,\n\t\t\t\t\twaitUntil: workerContext.waitUntil.bind(workerContext),\n\t\t\t\t\tpassThroughOnException: () => {\n\t\t\t\t\t\tisFailOpen = true;\n\t\t\t\t\t},\n\t\t\t\t};\n\n\t\t\t\tconst response = await handler(context);\n\n\t\t\t\tif (!(response instanceof Response)) {\n\t\t\t\t\tthrow new Error(\"Your Pages function should return a Response\");\n\t\t\t\t}\n\n\t\t\t\treturn cloneResponse(response);\n\t\t\t} else if (__FALLBACK_SERVICE__) {\n\t\t\t\t// There are no more handlers so finish with the fallback service (`env.ASSETS.fetch` in Pages' case)\n\t\t\t\tconst response = await env[__FALLBACK_SERVICE__].fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t} else {\n\t\t\t\t// There was not fallback service so actually make the request to the origin.\n\t\t\t\tconst response = await fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t}\n\t\t};\n\n\t\ttry {\n\t\t\treturn await next();\n\t\t} catch (error) {\n\t\t\tif (isFailOpen) {\n\t\t\t\tconst response = await env[__FALLBACK_SERVICE__].fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t}\n\n\t\t\tthrow error;\n\t\t}\n\t},\n};\n\n// This makes a Response mutable\nconst cloneResponse = (response: Response) =>\n\t// https://fetch.spec.whatwg.org/#null-body-status\n\tnew Response(\n\t\t[101, 204, 205, 304].includes(response.status) ? null : response.body,\n\t\tresponse\n\t);\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/home/sizzlebop/node_modules/wrangler/templates/pages-template-worker.ts\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/home/sizzlebop/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/home/sizzlebop/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/home/sizzlebop/node_modules/wrangler/templates/pages-template-worker.ts\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/bundle-F0376h/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/home/sizzlebop/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/bundle-F0376h/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/bundle-F0376h/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/pages-jGo0im/functionsWorker-0.9380529113682357.mjs\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/home/sizzlebop/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/home/sizzlebop/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/pages-jGo0im/functionsWorker-0.9380529113682357.mjs\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/bundle-UETRbs/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/home/sizzlebop/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/bundle-UETRbs/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/home/sizzlebop/Desktop/projects/dreamscape-ai/.wrangler/tmp/bundle-UETRbs/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;AAAA,IAAM,OAAO,oBAAI,IAAI;AAErB,SAAS,SAAS,SAAS,MAAM;AAChC,QAAM,MACL,mBAAmB,MAChB,UACA,IAAI;AAAA,KACH,OAAO,YAAY,WACjB,IAAI,QAAQ,SAAS,IAAI,IACzB,SACD;AAAA,EACH;AACH,MAAI,IAAI,QAAQ,IAAI,SAAS,SAAS,IAAI,aAAa,UAAU;AAChE,QAAI,CAAC,KAAK,IAAI,IAAI,SAAS,CAAC,GAAG;AAC9B,WAAK,IAAI,IAAI,SAAS,CAAC;AACvB,cAAQ;AAAA,QACP;AAAA,KACO,IAAI,SAAS,CAAC;AAAA;AAAA,MACtB;AAAA,IACD;AAAA,EACD;AACD;AAnBS;AAqBT,WAAW,QAAQ,IAAI,MAAM,WAAW,OAAO;AAAA,EAC9C,MAAM,QAAQ,SAAS,UAAU;AAChC,UAAM,CAAC,SAAS,IAAI,IAAI;AACxB,aAAS,SAAS,IAAI;AACtB,WAAO,QAAQ,MAAM,QAAQ,SAAS,QAAQ;AAAA,EAC/C;AACD,CAAC;;;;;AC7BD,IAAMA,QAAO,oBAAI,IAAI;AAErB,SAASC,UAAS,SAAS,MAAM;AAChC,QAAM,MACL,mBAAmB,MAChB,UACA,IAAI;KACH,OAAO,YAAY,WACjB,IAAI,QAAQ,SAAS,IAAI,IACzB,SACD;EACH;AACH,MAAI,IAAI,QAAQ,IAAI,SAAS,SAAS,IAAI,aAAa,UAAU;AAChE,QAAI,CAACD,MAAK,IAAI,IAAI,SAAS,CAAC,GAAG;AAC9B,MAAAA,MAAK,IAAI,IAAI,SAAS,CAAC;AACvB,cAAQ;QACP;KACO,IAAI,SAAS,CAAC;;MACtB;IACD;EACD;AACD;AAnBS,OAAAC,WAAA;AAAAC,QAAAD,WAAA,UAAA;AAqBT,WAAW,QAAQ,IAAI,MAAM,WAAW,OAAO;EAC9C,MAAM,QAAQ,SAAS,UAAU;AAChC,UAAM,CAAC,SAAS,IAAI,IAAI;AACxB,IAAAA,UAAS,SAAS,IAAI;AACtB,WAAO,QAAQ,MAAM,QAAQ,SAAS,QAAQ;EAC/C;AACD,CAAC;AC5BD,eAAsB,cAAc,SAAS;AACzC,MAAI;AAEF,UAAM,WAAW,MAAM,QAAQ,QAAQ,SAAS;AAChD,UAAM,YAAY,SAAS,IAAI,OAAO;AACtC,UAAM,wBAAwB,SAAS,IAAI,iBAAiB,KAAK;AACjE,QAAI;AAEJ,QAAI;AACF,wBAAkB,KAAK,MAAM,qBAAqB;IACpD,SAAS,GAAG;AACV,wBAAkB,CAAC;IACrB;AAGA,UAAM,YAAY,QAAQ,IAAI;AAC9B,UAAM,SAAS,QAAQ,IAAI;AAC3B,UAAM,YAAY,QAAQ,IAAI;AAE9B,QAAI,CAAC,aAAa,CAAC,UAAU,CAAC,WAAW;AACvC,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,OAAO;MACT,CAAC,GAAG;QACF,QAAQ;QACR,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH;AAGA,UAAM,cAAc,MAAM,UAAU,YAAY;AAChD,UAAM,SAAS,IAAI,WAAW,WAAW;AACzC,UAAM,cAAc,KAAK,OAAO,aAAa,MAAM,MAAM,MAAM,CAAC;AAChE,UAAM,UAAU,QAAQ,UAAU,IAAI,WAAW,WAAW;AAG5D,UAAM,YAAY,KAAK,OAAM,oBAAI,KAAK,GAAE,QAAQ,IAAI,GAAI;AACxD,UAAM,YAAY,MAAM,kBAAkB,aAAa,SAAS,GAAG,SAAS,EAAE;AAG9E,UAAM,qBAAqB,IAAI,SAAS;AACxC,uBAAmB,OAAO,QAAQ,OAAO;AACzC,uBAAmB,OAAO,WAAW,MAAM;AAC3C,uBAAmB,OAAO,aAAa,SAAS;AAChD,uBAAmB,OAAO,aAAa,SAAS;AAChD,uBAAmB,OAAO,UAAU,wBAAwB;AAG5D,UAAM,iBAAiB,MAAM,MAAM,mCAAmC,SAAS,iBAAiB;MAC9F,QAAQ;MACR,MAAM;IACR,CAAC;AAED,QAAI,CAAC,eAAe,IAAI;AACtB,YAAM,YAAY,MAAM,eAAe,KAAK;AAC5C,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,OAAO;QACP,SAAS;MACX,CAAC,GAAG;QACF,QAAQ;QACR,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH;AAEA,UAAM,eAAe,MAAM,eAAe,KAAK;AAG/C,UAAM,sBAAsB,CAAC;AAG7B,WAAO,QAAQ,eAAe,EAAE,QAAQ,CAAC,CAAC,KAAK,KAAK,MAAM;AACxD,UAAI,UAAU,MAAM;AAClB,4BAAoB,KAAK,GAAG;MAC9B,OAAO;AACL,4BAAoB,KAAK,GAAG,GAAG,IAAI,KAAK,EAAE;MAC5C;IACF,CAAC;AAGD,QAAI,oBAAoB,WAAW,GAAG;AACpC,0BAAoB,KAAK,oBAAoB;AAC7C,0BAAoB,KAAK,eAAe;IAC1C,OAAO;AAEL,0BAAoB,KAAK,eAAe;IAC1C;AAGA,UAAM,uBAAuB,oBAAoB,KAAK,GAAG;AACzD,UAAM,mBAAmB,8BAA8B,SAAS,iBAAiB,oBAAoB,IAAI,aAAa,SAAS;AAE/H,WAAO,IAAI,SAAS,KAAK,UAAU;MACjC,SAAS;MACT,UAAU,aAAa;MACvB,UAAU;MACV,WAAW,aAAa;IAC1B,CAAC,GAAG;MACF,SAAS;QACP,gBAAgB;QAChB,+BAA+B;MACjC;IACF,CAAC;EACH,SAAS,OAAO;AACd,YAAQ,MAAM,UAAU,KAAK;AAC7B,WAAO,IAAI,SAAS,KAAK,UAAU;MACjC,SAAS;MACT,OAAO,MAAM;IACf,CAAC,GAAG;MACF,QAAQ;MACR,SAAS;QACP,gBAAgB;QAChB,+BAA+B;MACjC;IACF,CAAC;EACH;AACF;AA1HoB;AAAAC,QAAA,eAAA,eAAA;AA6HpB,eAAe,kBAAkB,QAAQ;AAEvC,QAAM,UAAU,IAAI,YAAY;AAChC,QAAM,OAAO,QAAQ,OAAO,MAAM;AAGlC,QAAM,aAAa,MAAM,OAAO,OAAO,OAAO,SAAS,IAAI;AAG3D,QAAM,YAAY,MAAM,KAAK,IAAI,WAAW,UAAU,CAAC;AACvD,QAAM,UAAU,UAAU,IAAI,CAAA,MAAK,EAAE,SAAS,EAAE,EAAE,SAAS,GAAG,GAAG,CAAC,EAAE,KAAK,EAAE;AAE3E,SAAO;AACT;AAbe;AAAAA,QAAA,mBAAA,mBAAA;AC7HjB,eAAsBC,eAAc,SAAS;AAC3C,MAAI;AACF,YAAQ,IAAI,wDAAwD;AAGpE,UAAM,cAAc,MAAM,QAAQ,QAAQ,KAAK;AAC/C,UAAM,EAAE,OAAO,QAAQ,QAAQ,SAAS,aAAa,WAAW,IAAI;AAEpE,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,OAAO;MACT,CAAC,GAAG;QACF,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH;AAEA,YAAQ,IAAI,oCAAoC,SAAS,QAAQ;AAGjE,QAAI;AACJ,QAAI,iBAAiB;AAErB,QAAI,UAAU,aAAa;AAEzB,YAAM,gBAAgB,mBAAmB,MAAM;AAC/C,YAAM,OAAO,KAAK,MAAM,KAAK,OAAO,IAAI,GAAI;AAC5C,YAAM,YAAY,gCAAgC,aAAa,yBAAyB,IAAI;AAE5F,cAAQ,IAAI,qCAAqC,SAAS;AAE1D,YAAM,uBAAuB,MAAM,MAAM,SAAS;AAElD,UAAI,CAAC,qBAAqB,IAAI;AAC5B,cAAM,IAAI,MAAM,6BAA6B,qBAAqB,MAAM,KAAK,qBAAqB,UAAU,EAAE;MAChH;AAGA,qBAAe,MAAM,qBAAqB,KAAK;AAC/C,uBAAiB;IACnB,OAAO;AAEL,YAAM,gBAAgB,mBAAmB,MAAM;AAC/C,UAAI,SAAS,gCAAgC,aAAa,UAAU,SAAS,QAAQ;AAGrF,UAAI,QAAQ;AACV,cAAM,gBAAgB,mBAAmB,MAAM;AAC/C,kBAAU,WAAW,aAAa;MACpC;AAGA,UAAI,YAAY;AACd,kBAAU,eAAe,UAAU;MACrC;AAEA,cAAQ,IAAI,2CAA2C,MAAM;AAE7D,YAAM,uBAAuB,MAAM,MAAM,MAAM;AAE/C,UAAI,CAAC,qBAAqB,IAAI;AAC5B,cAAM,IAAI,MAAM,6BAA6B,qBAAqB,MAAM,KAAK,qBAAqB,UAAU,EAAE;MAChH;AAGA,YAAM,cAAc,qBAAqB,QAAQ,IAAI,cAAc,KAAK;AACxE,uBAAiB,YAAY,SAAS,kBAAkB;AAGxD,qBAAe,MAAM,qBAAqB,KAAK;IACjD;AAEA,YAAQ,IAAI,iDAAiD;AAC7D,YAAQ,IAAI,qBAAqB,cAAc;AAG/C,QAAI,aAAa;MACf,SAAS;MACT,OAAO,SAAS;IAClB;AAEA,QAAI,gBAAgB;AAClB,UAAI;AAEF,cAAM,WAAW,KAAK,MAAM,YAAY;AAGxC,YAAI,SAAS,MAAM;AACjB,qBAAW,OAAO,SAAS;QAC7B,WAAW,SAAS,SAAS;AAC3B,qBAAW,OAAO,SAAS;QAC7B,WAAW,SAAS,WAAW,SAAS,QAAQ,CAAC,KAAK,SAAS,QAAQ,CAAC,EAAE,SAAS;AACjF,qBAAW,OAAO,SAAS,QAAQ,CAAC,EAAE,QAAQ;QAChD,OAAO;AAEL,qBAAW,OAAO,KAAK,UAAU,QAAQ;QAC3C;AAGA,mBAAW,MAAM;MACnB,SAAS,YAAY;AACnB,gBAAQ,MAAM,gCAAgC,UAAU;AAExD,mBAAW,OAAO;AAClB,mBAAW,aAAa,WAAW;MACrC;IACF,OAAO;AAEL,iBAAW,OAAO;IACpB;AAGA,WAAO,IAAI,SAAS,KAAK,UAAU,UAAU,GAAG;MAC9C,SAAS;QACP,gBAAgB;QAChB,+BAA+B;MACjC;IACF,CAAC;EAEH,SAAS,OAAO;AACd,YAAQ,MAAM,4CAA4C,KAAK;AAE/D,WAAO,IAAI,SAAS,KAAK,UAAU;MACjC,SAAS;MACT,OAAO,MAAM,WAAW;IAC1B,CAAC,GAAG;MACF,QAAQ;MACR,SAAS;QACP,gBAAgB;QAChB,+BAA+B;MACjC;IACF,CAAC;EACH;AACF;AAxIsBA;AAAAD,QAAAC,gBAAA,eAAA;ACEtB,eAAsBA,eAAc,SAAS;AAC3C,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AAEF,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,IAAI,IAAI;AAEhB,QAAI,CAAC,KAAK;AACR,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,kBAAkB,CAAC;QAC3D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,iBAAiB,GAAG,EAAE;AAGlC,QAAI;AACF,YAAM,mBAAmB,IAAI,IAAI,QAAQ,QAAQ,GAAG;AACpD,uBAAiB,WAAW;AAE5B,YAAM,kBAAkB,MAAM,MAAM,kBAAkB;QACpD,QAAQ;QACR,SAAS,EAAE,gBAAgB,mBAAmB;QAC9C,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC;MAC9B,CAAC;AAED,UAAI,gBAAgB,IAAI;AACtB,cAAM,cAAc,MAAM,gBAAgB,KAAK;AAE/C,YAAI,YAAY,WAAW,YAAY,SAAS;AAC9C,kBAAQ,IAAI,wBAAwB,GAAG,iBAAiB;AACxD,iBAAO,IAAI;YACT,KAAK,UAAU;cACb,SAAS;cACT,SAAS,YAAY;cACrB,OAAO,YAAY,SAAS;cAC5B,QAAQ;YACV,CAAC;YACD,EAAE,QAAQ;UACZ;QACF;MACF;IACF,SAAS,cAAc;AACrB,cAAQ,MAAM,iCAAiC,GAAG,KAAK,aAAa,OAAO,EAAE;IAC/E;AAGA,QAAI;AACF,YAAM,iBAAiB,IAAI,IAAI,QAAQ,QAAQ,GAAG;AAClD,qBAAe,WAAW;AAE1B,YAAM,gBAAgB,MAAM,MAAM,gBAAgB;QAChD,QAAQ;QACR,SAAS,EAAE,gBAAgB,mBAAmB;QAC9C,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC;MAC9B,CAAC;AAED,UAAI,cAAc,IAAI;AACpB,cAAM,YAAY,MAAM,cAAc,KAAK;AAE3C,YAAI,UAAU,WAAW,UAAU,SAAS;AAC1C,kBAAQ,IAAI,wBAAwB,GAAG,oBAAoB;AAC3D,iBAAO,IAAI;YACT,KAAK,UAAU;cACb,SAAS;cACT,SAAS,UAAU;cACnB,OAAO,UAAU,SAAS;cAC1B,QAAQ,UAAU,UAAU;YAC9B,CAAC;YACD,EAAE,QAAQ;UACZ;QACF;MACF;IACF,SAAS,YAAY;AACnB,cAAQ,MAAM,2BAA2B,GAAG,KAAK,WAAW,OAAO,EAAE;IACvE;AAGA,UAAM,WAAW;MACf,EAAE,MAAM,cAAc,MAAM,kBAAkB;MAC9C,EAAE,MAAM,eAAe,MAAM,mBAAmB;MAChD,EAAE,MAAM,aAAa,MAAM,iBAAiB;IAC9C;AAEA,eAAW,WAAW,UAAU;AAC9B,UAAI;AACF,cAAM,aAAa,IAAI,IAAI,QAAQ,QAAQ,GAAG;AAC9C,mBAAW,WAAW,QAAQ;AAE9B,cAAM,kBAAkB,MAAM,MAAM,YAAY;UAC9C,QAAQ;UACR,SAAS,EAAE,gBAAgB,mBAAmB;UAC9C,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC;QAC9B,CAAC;AAED,YAAI,gBAAgB,IAAI;AACtB,gBAAM,cAAc,MAAM,gBAAgB,KAAK;AAE/C,cAAI,YAAY,WAAW,YAAY,SAAS;AAC9C,oBAAQ,IAAI,wBAAwB,GAAG,SAAS,QAAQ,IAAI,EAAE;AAC9D,mBAAO,IAAI;cACT,KAAK,UAAU;gBACb,SAAS;gBACT,SAAS,YAAY;gBACrB,OAAO,YAAY,SAAS;gBAC5B,QAAQ,QAAQ;cAClB,CAAC;cACD,EAAE,QAAQ;YACZ;UACF;QACF;MACF,SAAS,cAAc;AACrB,gBAAQ,MAAM,GAAG,QAAQ,IAAI,wBAAwB,GAAG,KAAK,aAAa,OAAO,EAAE;MACrF;IACF;AAGA,YAAQ,IAAI,oCAAoC,GAAG,gCAAgC;AAGnF,QAAI;AACF,YAAM,kBAAkB,IAAI,IAAI,QAAQ,QAAQ,GAAG;AACnD,sBAAgB,WAAW;AAE3B,YAAM,uBAAuB,MAAM,MAAM,iBAAiB;QACxD,QAAQ;QACR,SAAS,EAAE,gBAAgB,mBAAmB;QAC9C,MAAM,KAAK,UAAU;UACnB,OAAO;UACP,QAAQ,8EAA8E,GAAG;UACzF,QAAQ;UACR,YAAY;QACd,CAAC;MACH,CAAC;AAED,YAAM,mBAAmB,MAAM,qBAAqB,KAAK;AAEzD,UAAI,iBAAiB,WAAW,iBAAiB,MAAM;AACrD,eAAO,IAAI;UACT,KAAK,UAAU;YACb,SAAS;YACT,SAAS,iBAAiB;YAC1B,OAAO,yBAAyB,GAAG;YACnC,QAAQ;YACR,WAAW;UACb,CAAC;UACD,EAAE,QAAQ;QACZ;MACF;IACF,SAAS,mBAAmB;AAC1B,cAAQ,MAAM,yCAAyC,kBAAkB,OAAO,EAAE;IACpF;AAGA,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO;QACP;MACF,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EAEF,SAAS,OAAO;AACd,YAAQ,MAAM,uBAAuB,KAAK,EAAE;AAE5C,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM;MACf,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AA1LsBA;AAAAD,QAAAC,gBAAA,eAAA;ACFtB,eAAsBA,eAAc,SAAS;AAC3C,MAAI;AACF,YAAQ,IAAI,qDAAqD;AAGjE,UAAM,eAAe,QAAQ,IAAI;AACjC,UAAM,YAAY;AAElB,YAAQ,IAAI,6BAA6B,CAAC,CAAC,YAAY;AACvD,YAAQ,IAAI,oCAAoC,OAAO,KAAK,QAAQ,GAAG,EAAE,KAAK,IAAI,CAAC;AAEnF,QAAI,CAAC,cAAc;AACjB,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,OAAO;QACP,eAAe,OAAO,KAAK,QAAQ,GAAG,EAAE;MAC1C,CAAC,GAAG;QACF,QAAQ;;QACR,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH;AAGA,UAAM,cAAc,QAAQ,QAAQ,QAAQ,IAAI,cAAc;AAC9D,UAAM,YAAY,MAAM,QAAQ,QAAQ,YAAY;AAEpD,YAAQ,IAAI,gCAAgC,UAAU,YAAY,OAAO;AACzE,YAAQ,IAAI,iBAAiB,WAAW;AAGxC,QAAI,UAAU,aAAa,KAAK;AAC9B,cAAQ,IAAI,+CAA+C;AAC3D,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,SAAS,EAAE,SAAS,CAAC,EAAE;;MACzB,CAAC,GAAG;QACF,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH;AAGA,UAAM,gBAAgB,IAAI,QAAQ;AAElC,kBAAc,OAAO,gBAAgB,mCAAmC;AACxE,kBAAc,OAAO,iBAAiB,SAAS,KAAK,YAAY,YAAY,CAAC,EAAE;AAC/E,kBAAc,OAAO,UAAU,kBAAkB;AAGjD,UAAM,sBAAsB,IAAI,IAAI,SAAS;AAC7C,wBAAoB,aAAa,OAAO,SAAS,sBAAsB;AACvE,wBAAoB,aAAa,OAAO,oBAAoB,MAAM;AAClE,wBAAoB,aAAa,OAAO,mBAAmB,MAAM;AACjE,wBAAoB,aAAa,OAAO,sBAAsB,GAAG;AACjE,wBAAoB,aAAa,OAAO,oBAAoB,GAAG;AAE/D,YAAQ,IAAI,kCAAkC,oBAAoB,SAAS,CAAC;AAC5E,YAAQ,IAAI,wFAAwF;AAEpG,QAAI;AAEF,YAAM,iBAAiB,MAAM,MAAM,oBAAoB,SAAS,GAAG;QACjE,QAAQ;QACR,SAAS;QACT,MAAM;MACR,CAAC;AAGD,YAAM,eAAe,MAAM,eAAe,KAAK;AAC/C,UAAI;AAEJ,UAAI;AACF,yBAAiB,KAAK,MAAM,YAAY;AACxC,gBAAQ,IAAI,wBAAwB,KAAK,UAAU,cAAc,EAAE,UAAU,GAAG,GAAG,IAAI,KAAK;MAC9F,SAAS,YAAY;AACnB,gBAAQ,IAAI,oCAAoC,aAAa,UAAU,GAAG,GAAG,CAAC;AAC9E,yBAAiB,EAAE,SAAS,CAAC,EAAE;MACjC;AAEA,UAAI,CAAC,eAAe,IAAI;AACtB,gBAAQ,IAAI,qBAAqB,eAAe,QAAQ,YAAY;AAGpE,YAAI,eAAe,WAAW,KAAK;AACjC,iBAAO,IAAI,SAAS,KAAK,UAAU;YACjC,SAAS;YACT,SAAS,EAAE,SAAS,CAAC,EAAE;;UACzB,CAAC,GAAG;YACF,SAAS;cACP,gBAAgB;cAChB,+BAA+B;YACjC;UACF,CAAC;QACH;AAEA,eAAO,IAAI,SAAS,KAAK,UAAU;UACjC,SAAS;UACT,OAAO,qBAAqB,eAAe,MAAM;UACjD,SAAS;QACX,CAAC,GAAG;UACF,QAAQ;;UACR,SAAS;YACP,gBAAgB;YAChB,+BAA+B;UACjC;QACF,CAAC;MACH;AAGA,cAAQ,IAAI,uCAAuC;AAGnD,YAAM,aAAa,kBACD,eAAe,WACf,eAAe,QAAQ,SAAS,KAChC,eAAe,QAAQ,CAAC,EAAE,gBAC1B,eAAe,QAAQ,CAAC,EAAE,aAAa,SAAS;AAElE,UAAI,YAAY;AACd,gBAAQ,IAAI,wBAAwB,eAAe,QAAQ,CAAC,EAAE,aAAa,CAAC,EAAE,UAAU;MAC1F,OAAO;AACL,gBAAQ,IAAI,6BAA6B;MAC3C;AAEA,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,SAAS;MACX,CAAC,GAAG;QACF,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH,SAAS,YAAY;AACnB,cAAQ,MAAM,wCAAwC,UAAU;AAChE,aAAO,IAAI,SAAS,KAAK,UAAU;QACjC,SAAS;QACT,OAAO;QACP,SAAS,WAAW;MACtB,CAAC,GAAG;QACF,QAAQ;;QACR,SAAS;UACP,gBAAgB;UAChB,+BAA+B;QACjC;MACF,CAAC;IACH;EAEF,SAAS,OAAO;AACd,YAAQ,MAAM,qCAAqC,KAAK;AACxD,WAAO,IAAI,SAAS,KAAK,UAAU;MACjC,SAAS;MACT,OAAO,MAAM;MACb,OAAO,MAAM;IACf,CAAC,GAAG;MACF,QAAQ;;MACR,SAAS;QACP,gBAAgB;QAChB,+BAA+B;MACjC;IACF,CAAC;EACH;AACF;AAvKsBA;AAAAD,QAAAC,gBAAA,eAAA;AA0KtB,eAAsB,mBAAmB;AACvC,UAAQ,IAAI,wDAAwD;AACpE,SAAO,IAAI,SAAS,MAAM;IACxB,SAAS;MACP,+BAA+B;MAC/B,gCAAgC;MAChC,gCAAgC;MAChC,0BAA0B;IAC5B;EACF,CAAC;AACH;AAVsB;AAAAD,QAAA,kBAAA,kBAAA;AC1KtB,eAAsB,UAAU,SAAS;AAEvC,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AACF,QAAI,QAAQ,QAAQ,WAAW,QAAQ;AACrC,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qBAAqB,CAAC;QAC9D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,KAAK,SAAS,IAAI;AAE1B,QAAI,CAAC,KAAK;AACR,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,kBAAkB,CAAC;QAC3D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,uBAAuB,GAAG,EAAE;AAGxC,UAAM,SAAS,QAAQ,IAAI;AAC3B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,mCAAmC,CAAC;QAC5E,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,YAAQ,IAAI,6BAA6B,GAAG,EAAE;AAE9C,UAAM,WAAW,MAAM,MAAM,sCAAsC;MACjE,QAAQ;MACR,SAAS;QACP,gBAAgB;QAChB,iBAAiB,UAAU,MAAM;MACnC;MACA,MAAM,KAAK,UAAU;QACnB;QACA,YAAY,aAAa;QACzB,UAAU;;QACV,UAAU;;QACV,UAAU;;MACZ,CAAC;IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,wBAAwB,SAAS,MAAM,MAAM,SAAS,EAAE;AACtE,aAAO,IAAI;QACT,KAAK,UAAU;UACb,SAAS;UACT,OAAO,0BAA0B,SAAS,MAAM,IAAI,SAAS,UAAU;QACzE,CAAC;QACD,EAAE,QAAQ,SAAS,QAAQ,QAAQ;MACrC;IACF;AAGA,UAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,QAAI,CAAC,KAAK,SAAS;AACjB,aAAO,IAAI;QACT,KAAK,UAAU;UACb,SAAS;UACT,OAAO,KAAK,SAAS;QACvB,CAAC;QACD,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,UAAU,KAAK,MAAM,YAAY,KAAK,MAAM,QAAQ,KAAK,MAAM,QAAQ;AAE7E,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT;QACA,OAAO,KAAK,MAAM,SAAS;QAC3B,SAAS;QACT,KAAK,KAAK,UAAU,IAAI,EAAE,UAAU,GAAG,GAAG;;MAC5C,CAAC;MACD,EAAE,QAAQ;IACZ;EACF,SAAS,OAAO;AACd,YAAQ,MAAM,6BAA6B,KAAK;AAEhD,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM,WAAW;MAC1B,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AA/GsB;AAAAA,QAAA,WAAA,WAAA;ACDtB,eAAsBE,WAAU,SAAS;AAEvC,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AAEF,QAAI,QAAQ,QAAQ,WAAW,QAAQ;AACrC,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qBAAqB,CAAC;QAC9D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,KAAK,WAAW,SAAS,IAAI;AAGrC,QAAI,CAAC,WAAW;AACd,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,kBAAkB,CAAC;QAC3D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,2BAA2B,SAAS,EAAE;AAGlD,UAAM,WAAW;MACf,EAAE,MAAM,aAAa,MAAM,sBAAsB;MACjD,EAAE,MAAM,cAAc,MAAM,kBAAkB;MAC9C,EAAE,MAAM,eAAe,MAAM,mBAAmB;MAChD,EAAE,MAAM,aAAa,MAAM,iBAAiB;IAC9C;AAEA,QAAI,YAAY;AAChB,QAAI,iBAAiB,CAAC;AAGtB,eAAW,WAAW,UAAU;AAC9B,UAAI;AACF,gBAAQ,IAAI,UAAU,QAAQ,IAAI,aAAa;AAG/C,YAAI;AACJ,YAAI,QAAQ,QAAQ,IAAI,SAAS,WAAW,KAAK,QAAQ,QAAQ,IAAI,SAAS,WAAW,GAAG;AAE1F,uBAAa,UAAU,QAAQ,QAAQ,QAAQ,IAAI,MAAM,CAAC,GAAG,QAAQ,IAAI;QAC3E,OAAO;AAEL,gBAAM,MAAM,IAAI,IAAI,QAAQ,QAAQ,GAAG;AACvC,uBAAa,GAAG,IAAI,QAAQ,KAAK,IAAI,IAAI,GAAG,QAAQ,IAAI;QAC1D;AAEA,gBAAQ,IAAI,uBAAuB,UAAU,EAAE;AAC/C,cAAM,kBAAkB,MAAM,MAAM,YAAY;UAC9C,QAAQ;UACR,SAAS;YACP,gBAAgB;UAClB;UACA,MAAM,KAAK,UAAU;YACnB,KAAK;YACL;UACF,CAAC;QACH,CAAC;AAED,YAAI,gBAAgB,IAAI;AACtB,gBAAM,cAAc,MAAM,gBAAgB,KAAK;AAE/C,cAAI,YAAY,WAAW,YAAY,SAAS;AAC9C,oBAAQ,IAAI,GAAG,QAAQ,IAAI,2BAA2B,YAAY,QAAQ,MAAM,mBAAmB;AAGnG,mBAAO,IAAI;cACT,KAAK,UAAU;gBACb,SAAS;gBACT,SAAS,YAAY;gBACrB,SAAS,QAAQ;gBACjB,YAAY;cACd,CAAC;cACD,EAAE,QAAQ;YACZ;UACF,OAAO;AAEL,2BAAe,KAAK;cAClB,SAAS,QAAQ;cACjB,SAAS;cACT,OAAO,YAAY,SAAS;YAC9B,CAAC;AACD,oBAAQ,IAAI,GAAG,QAAQ,IAAI,oBAAoB,YAAY,SAAS,qBAAqB,EAAE;UAC7F;QACF,OAAO;AAEL,gBAAM,YAAY,MAAM,gBAAgB,KAAK;AAC7C,yBAAe,KAAK;YAClB,SAAS,QAAQ;YACjB,SAAS;YACT,OAAO,GAAG,gBAAgB,MAAM,IAAI,gBAAgB,UAAU,KAAK,SAAS;UAC9E,CAAC;AACD,kBAAQ,IAAI,GAAG,QAAQ,IAAI,+BAA+B,gBAAgB,MAAM,KAAK,SAAS,EAAE;QAClG;MACF,SAAS,cAAc;AAErB,uBAAe,KAAK;UAClB,SAAS,QAAQ;UACjB,SAAS;UACT,OAAO,aAAa;QACtB,CAAC;AACD,oBAAY;AACZ,gBAAQ,MAAM,iBAAiB,QAAQ,IAAI,aAAa,YAAY;MACtE;IACF;AAGA,YAAQ,MAAM,8BAA8B;AAE5C,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO;QACP,WAAW,WAAW;QACtB;MACF,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF,SAAS,OAAO;AACd,YAAQ,MAAM,iCAAiC,KAAK;AAEpD,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM,WAAW;MAC1B,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AAlJsBA;AAAAF,QAAAE,YAAA,WAAA;ACAtB,eAAsBA,WAAU,SAAS;AAEvC,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AACF,QAAI,QAAQ,QAAQ,WAAW,QAAQ;AACrC,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qBAAqB,CAAC;QAC9D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,KAAK,SAAS,IAAI;AAE1B,QAAI,CAAC,KAAK;AACR,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,kBAAkB,CAAC;QAC3D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,6BAA6B,GAAG,EAAE;AAG9C,UAAM,SAAS,QAAQ,IAAI;AAC3B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,yCAAyC,CAAC;QAClF,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,SAAS,6CAA6C,MAAM;AAElE,YAAQ,IAAI,gCAAgC,MAAM,EAAE;AACpD,YAAQ,IAAI,kBAAkB,GAAG,EAAE;AAGnC,QAAI;AAEF,YAAM,cAAc;QAClB;QACA,YAAY,WAAW,SAAS;QAChC,cAAc;QACd,iBAAiB;UACf,SAAS;UACT,cAAc;UACd,cAAc;UACd,mBAAmB,CAAC;QACtB;QACA,gBAAgB;UACd,UAAU;YACR,OAAO;YACP,QAAQ;UACV;UACA,cAAc;UACd,oBAAoB,CAAC;QACvB;MACF;AAEA,cAAQ,IAAI,sBAAsB,KAAK,UAAU,aAAa,MAAM,CAAC,CAAC,EAAE;AAGxE,YAAM,WAAW,MAAM,MAAM,QAAQ;QACnC,QAAQ;QACR,SAAS;UACP,gBAAgB;QAClB;QACA,MAAM,KAAK,UAAU;UACnB,SAAS;;QACX,CAAC;MACH,CAAC;AAGD,cAAQ,IAAI,wCAAwC,SAAS,MAAM,EAAE;AAErE,UAAI,CAAC,SAAS,IAAI;AAChB,gBAAQ,MAAM,wBAAwB,SAAS,MAAM,IAAI,SAAS,UAAU,EAAE;AAC9E,cAAM,YAAY,MAAM,SAAS,KAAK,EAAE,MAAM,CAAA,MAAK,+BAA+B;AAClF,gBAAQ,MAAM,kBAAkB,SAAS,EAAE;AAG3C,gBAAQ,IAAI,qCAAqC;AACjD,cAAM,cAAc,GAAG,MAAM,QAAQ,mBAAmB,GAAG,CAAC,eAAe,WAAW,SAAS,WAAW;AAE1G,cAAM,mBAAmB,MAAM,MAAM,WAAW;AAChD,YAAI,CAAC,iBAAiB,IAAI;AACxB,iBAAO,IAAI;YACT,KAAK,UAAU;cACb,SAAS;cACT,OAAO,+BAA+B,SAAS,MAAM,IAAI,SAAS,UAAU;cAC5E,SAAS;YACX,CAAC;YACD,EAAE,QAAQ,SAAS,QAAQ,QAAQ;UACrC;QACF;AAEA,eAAO,wBAAwB,kBAAkB,UAAU,OAAO;MACpE;AAEA,aAAO,wBAAwB,UAAU,UAAU,OAAO;IAE5D,SAAS,OAAO;AACd,cAAQ,MAAM,8BAA8B,KAAK;AACjD,aAAO,IAAI;QACT,KAAK,UAAU;UACb,SAAS;UACT,OAAO,MAAM,WAAW;QAC1B,CAAC;QACD,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;EACF,SAAS,OAAO;AACd,YAAQ,MAAM,mCAAmC,KAAK;AAEtD,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM,WAAW;MAC1B,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AAxIsBA;AAAAF,QAAAE,YAAA,WAAA;AA2ItB,eAAe,wBAAwB,UAAU,UAAU,SAAS;AAElE,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AAEvD,MAAI;AACJ,MAAI,UAAU;AAEd,MAAI,eAAe,YAAY,SAAS,kBAAkB,GAAG;AAC3D,WAAO,MAAM,SAAS,KAAK;AAG3B,QAAI,QAAQ,KAAK,SAAS;AAExB,gBAAU,KAAK;IACjB,WAAW,QAAQ,KAAK,aAAa;AAEnC,gBAAU,KAAK;IACjB,OAAO;AAEL,gBAAU,KAAK,UAAU,IAAI;IAC/B;EACF,OAAO;AAEL,cAAU,MAAM,SAAS,KAAK;EAChC;AAGA,MAAI,mBAAmB;AAEvB,MAAI,aAAa,QAAQ,SAAS,OAAO,KAAK,QAAQ,SAAS,OAAO,IAAI;AAExE,uBAAmB,QAChB,QAAQ,uDAAuD,EAAE,EACjE,QAAQ,oDAAoD,EAAE,EAC9D,QAAQ,iDAAiD,EAAE,EAC3D,QAAQ,8CAA8C,EAAE,EACxD,QAAQ,uDAAuD,EAAE;AAGpE,UAAM,YAAY,iBAAiB,MAAM,gCAAgC,KACvD,iBAAiB,MAAM,sCAAsC,KAC7D,iBAAiB,MAAM,uDAAuD,KAC9E,iBAAiB,MAAM,0DAA0D;AAEnG,QAAI,aAAa,UAAU,CAAC,GAAG;AAE7B,yBAAmB,UAAU,CAAC,EAC3B,QAAQ,YAAY,GAAG,EACvB,QAAQ,QAAQ,GAAG,EACnB,KAAK;IACV,OAAO;AAEL,yBAAmB,iBAChB,QAAQ,YAAY,GAAG,EACvB,QAAQ,QAAQ,GAAG,EACnB,KAAK;IACV;EACF;AAEA,SAAO,IAAI;IACT,KAAK,UAAU;MACb,SAAS;MACT,SAAS;MACT,SAAS;MACT,KAAK,OAAO,YAAY,WAAW,QAAQ,UAAU,GAAG,GAAG,KAAK,QAAQ,SAAS,MAAM,QAAQ,MAAM,KAAK,UAAU,QAAQ,CAAC,CAAC,EAAE,UAAU,GAAG,GAAG;IAClJ,CAAC;IACD,EAAE,QAAQ;EACZ;AACF;AApEe;AAAAF,QAAA,yBAAA,yBAAA;AC1If,eAAsBE,WAAU,SAAS;AAEvC,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AAEF,QAAI,QAAQ,QAAQ,WAAW,QAAQ;AACrC,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qBAAqB,CAAC;QAC9D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,MAAM,IAAI;AAGlB,QAAI,CAAC,OAAO;AACV,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,2BAA2B,CAAC;QACpE,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,iCAAiC,KAAK,EAAE;AAGpD,UAAM,gBAAgB,MAAM,YAAY,EAAE,WAAW,UAAU,IAAI,QAAQ,YAAY,KAAK;AAC5F,UAAM,eAAe,mBAAmB,aAAa;AAGrD,UAAM,OAAO;AAGb,UAAM,YAAY,gCAAgC,YAAY,yBAAyB,IAAI;AAC3F,YAAQ,IAAI,6BAA6B,SAAS,EAAE;AAEpD,UAAM,iBAAiB,MAAM,MAAM,WAAW;MAC5C,SAAS;QACP,UAAU;MACZ;IACF,CAAC;AAED,QAAI,CAAC,eAAe,IAAI;AACtB,YAAM,IAAI,MAAM,uCAAuC,eAAe,MAAM,KAAK,eAAe,UAAU,EAAE;IAC9G;AAGA,UAAM,eAAe,MAAM,eAAe,KAAK;AAC/C,YAAQ,IAAI,sBAAsB,YAAY;AAE9C,QAAI;AACJ,QAAI;AACF,qBAAe,KAAK,MAAM,YAAY;IACxC,SAAS,KAAK;AACZ,cAAQ,MAAM,gCAAgC,GAAG;AACjD,YAAM,IAAI,MAAM,gDAAgD;IAClE;AAEA,YAAQ,IAAI,4BAA4B,OAAO,KAAK,YAAY,CAAC;AAGjE,QAAIJ,SAAO,CAAC;AAGZ,QAAI,aAAa,QAAQ,MAAM,QAAQ,aAAa,IAAI,GAAG;AACzD,cAAQ,IAAI,sCAAsC;AAClDA,MAAAA,SAAO,aAAa,KAAK,IAAI,CAAA,SAAQ;AACnC,YAAI,OAAO,SAAS,UAAU;AAE5B,iBAAO;YACL,OAAO;YACP,KAAK;UACP;QACF,OAAO;AAEL,iBAAO;YACL,OAAO,KAAK,SAAS;YACrB,KAAK,KAAK,OAAO;YACjB,SAAS,KAAK;UAChB;QACF;MACF,CAAC;IACH,OAAO;AAGL,YAAM,aAAa,OAAO,KAAK,YAAY,EAAE;QAAK,CAAA,QAChD,MAAM,QAAQ,aAAa,GAAG,CAAC,KAC/B,aAAa,GAAG,EAAE,SAAS;MAC7B;AAEA,UAAI,cAAc,aAAa,UAAU,GAAG;AAC1CA,QAAAA,SAAO,aAAa,UAAU,EAAE,IAAI,CAAA,SAAQ;AAC1C,cAAI,OAAO,SAAS,UAAU;AAC5B,mBAAO;cACL,OAAO;cACP,KAAK;YACP;UACF,OAAO;AACL,mBAAO;cACL,OAAO,KAAK,SAAS;cACrB,KAAK,KAAK,OAAO;cACjB,SAAS,KAAK;YAChB;UACF;QACF,CAAC;MACH;IACF;AAEA,YAAQ,IAAI,SAASA,OAAK,MAAM,4BAA4BA,MAAI;AAEhE,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,MAAAA;QACA,YAAY,KAAK,UAAU,YAAY;MACzC,CAAC;MACD,EAAE,QAAQ;IACZ;EACF,SAAS,OAAO;AACd,YAAQ,MAAM,iCAAiC,KAAK;AAEpD,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM;MACf,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AA7IsBI;AAAAF,QAAAE,YAAA,WAAA;ACDtB,eAAsBA,WAAU,SAAS;AAEvC,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AACF,QAAI,QAAQ,QAAQ,WAAW,QAAQ;AACrC,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qBAAqB,CAAC;QAC9D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,KAAK,SAAS,IAAI;AAE1B,QAAI,CAAC,KAAK;AACR,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,kBAAkB,CAAC;QAC3D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,wBAAwB,GAAG,EAAE;AAGzC,UAAM,SAAS,QAAQ,IAAI;AAC3B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,gCAAgC,CAAC;QACzE,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,SAAS,sCAAsC,MAAM,QAAQ,mBAAmB,GAAG,CAAC,GAAG,WAAW,iBAAiB,EAAE;AAE3H,YAAQ,IAAI,uBAAuB,MAAM,EAAE;AAG3C,UAAM,WAAW,MAAM,MAAM,MAAM;AAEnC,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,qBAAqB,SAAS,MAAM,MAAM,SAAS,EAAE;AACnE,aAAO,IAAI;QACT,KAAK,UAAU;UACb,SAAS;UACT,OAAO,uBAAuB,SAAS,MAAM,IAAI,SAAS,UAAU;QACtE,CAAC;QACD,EAAE,QAAQ,SAAS,QAAQ,QAAQ;MACrC;IACF;AAGA,UAAM,UAAU,MAAM,SAAS,KAAK;AAGpC,UAAM,cAAc,QACjB,QAAQ,uDAAuD,EAAE,EACjE,QAAQ,oDAAoD,EAAE,EAC9D,QAAQ,iDAAiD,EAAE;AAI9D,QAAI,mBAAmB;AAIvB,UAAM,eAAe,YAAY,MAAM,sCAAsC,KACzD,YAAY,MAAM,gCAAgC;AAGtE,UAAM,kBAAkB,YAAY,MAAM,oEAAoE,KACxF,YAAY,MAAM,qDAAqD,KACvE,YAAY,MAAM,0DAA0D,KAC5E,YAAY,MAAM,qDAAqD;AAG7F,UAAM,WAAW,YAAY,MAAM,qEAAqE,KACzF,YAAY,MAAM,kEAAkE,KACpF,YAAY,MAAM,0EAA0E;AAG3G,UAAM,cAAc,YAAY,MAAM,6DAA6D,KACjF,YAAY,MAAM,4EAA4E;AAGhH,QAAI,gBAAgB,aAAa,CAAC,GAAG;AACnC,yBAAmB,aAAa,CAAC;AACjC,cAAQ,IAAI,yCAAyC;IACvD,WAAW,YAAY,SAAS,CAAC,GAAG;AAClC,yBAAmB,SAAS,CAAC;AAC7B,cAAQ,IAAI,gDAAgD;IAC9D,WAAW,eAAe,YAAY,CAAC,GAAG;AACxC,yBAAmB,YAAY,CAAC;AAChC,cAAQ,IAAI,kDAAkD;IAChE,WAAW,mBAAmB,gBAAgB,CAAC,GAAG;AAChD,yBAAmB,gBAAgB,CAAC;AACpC,cAAQ,IAAI,oCAAoC;IAClD,OAAO;AAEL,YAAM,YAAY,YAAY,MAAM,gCAAgC;AACpE,UAAI,aAAa,UAAU,CAAC,GAAG;AAC7B,YAAI,cAAc,UAAU,CAAC;AAG7B,sBAAc,YACX,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,+BAA+B,EAAE,EACzC,QAAQ,mCAAmC,EAAE,EAC7C,QAAQ,qEAAqE,EAAE,EAC/E,QAAQ,kEAAkE,EAAE,EAC5E,QAAQ,wEAAwE,EAAE;AAErF,2BAAmB;AACnB,gBAAQ,IAAI,uCAAuC;MACrD,OAAO;AAEL,2BAAmB;AACnB,gBAAQ,IAAI,uCAAuC;MACrD;IACF;AAIA,uBAAmB,iBAChB,QAAQ,gBAAgB,SAAS,EACjC,QAAQ,iCAAiC,EAAE,EAC3C,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,+BAA+B,EAAE;AAG5C,UAAM,cAAc,iBACjB,QAAQ,+BAA+B,UAAU,EACjD,QAAQ,+BAA+B,WAAW,EAClD,QAAQ,+BAA+B,YAAY,EACnD,QAAQ,+BAA+B,aAAa,EACpD,QAAQ,+BAA+B,cAAc,EACrD,QAAQ,+BAA+B,eAAe,EACtD,QAAQ,6BAA6B,QAAQ,EAC7C,QAAQ,gBAAgB,IAAI,EAC5B,QAAQ,+BAA+B,aAAQ,EAC/C,QAAQ,yDAAyD,UAAU,EAC3E,QAAQ,YAAY,EAAE,EACtB,QAAQ,YAAY,MAAM,EAC1B,QAAQ,WAAW,GAAG,EACtB,QAAQ,SAAS,GAAG,EACpB,QAAQ,SAAS,GAAG,EACpB,QAAQ,UAAU,GAAG,EACrB,QAAQ,WAAW,GAAG,EACtB,KAAK;AAGR,UAAM,qBAAqB;AAC3B,UAAM,mBAAmB,YAAY,SAAS,qBAAqB,cAAc;AAGjF,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,SAAS;QACT,SAAS;QACT,KAAK,QAAQ,UAAU,GAAG,GAAG,KAAK,QAAQ,SAAS,MAAM,QAAQ;;MACnE,CAAC;MACD,EAAE,QAAQ;IACZ;EACF,SAAS,OAAO;AACd,YAAQ,MAAM,8BAA8B,KAAK;AAEjD,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM,WAAW;MAC1B,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AA7LsBA;AAAAF,QAAAE,YAAA,WAAA;ACAtB,eAAsBA,WAAU,SAAS;AAEvC,QAAM,UAAU;IACd,+BAA+B;IAC/B,gCAAgC;IAChC,gCAAgC;IAChC,gBAAgB;EAClB;AAGA,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM,EAAE,QAAQ,CAAC;EACvC;AAEA,MAAI;AACF,QAAI,QAAQ,QAAQ,WAAW,QAAQ;AACrC,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qBAAqB,CAAC;QAC9D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,UAAM,OAAO,MAAM,QAAQ,QAAQ,KAAK;AACxC,UAAM,EAAE,KAAK,SAAS,IAAI;AAE1B,QAAI,CAAC,KAAK;AACR,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,kBAAkB,CAAC;QAC3D,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAEA,YAAQ,IAAI,yBAAyB,GAAG,EAAE;AAG1C,UAAM,SAAS,QAAQ,IAAI;AAC3B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI;QACT,KAAK,UAAU,EAAE,SAAS,OAAO,OAAO,qCAAqC,CAAC;QAC9E,EAAE,QAAQ,KAAK,QAAQ;MACzB;IACF;AAGA,YAAQ,IAAI,+BAA+B,GAAG,EAAE;AAEhD,UAAM,WAAW,MAAM,MAAM,8CAA8C,mBAAmB,GAAG,CAAC,YAAY,WAAW,SAAS,OAAO,IAAI;MAC3I,QAAQ;MACR,SAAS;QACP,aAAa;MACf;IACF,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,cAAQ,MAAM,0BAA0B,SAAS,MAAM,MAAM,SAAS,EAAE;AACxE,aAAO,IAAI;QACT,KAAK,UAAU;UACb,SAAS;UACT,OAAO,4BAA4B,SAAS,MAAM,IAAI,SAAS,UAAU;QAC3E,CAAC;QACD,EAAE,QAAQ,SAAS,QAAQ,QAAQ;MACrC;IACF;AAGA,UAAM,UAAU,MAAM,SAAS,KAAK;AAGpC,UAAM,cAAc,QACjB,QAAQ,uDAAuD,EAAE,EACjE,QAAQ,oDAAoD,EAAE,EAC9D,QAAQ,iDAAiD,EAAE;AAI9D,QAAI,mBAAmB;AAIvB,UAAM,eAAe,YAAY,MAAM,sCAAsC,KACzD,YAAY,MAAM,gCAAgC;AAGtE,UAAM,kBAAkB,YAAY,MAAM,oEAAoE,KACxF,YAAY,MAAM,qDAAqD,KACvE,YAAY,MAAM,0DAA0D,KAC5E,YAAY,MAAM,qDAAqD;AAG7F,UAAM,WAAW,YAAY,MAAM,qEAAqE,KACzF,YAAY,MAAM,kEAAkE,KACpF,YAAY,MAAM,0EAA0E;AAG3G,UAAM,cAAc,YAAY,MAAM,6DAA6D,KACjF,YAAY,MAAM,4EAA4E;AAGhH,QAAI,gBAAgB,aAAa,CAAC,GAAG;AACnC,yBAAmB,aAAa,CAAC;AACjC,cAAQ,IAAI,yCAAyC;IACvD,WAAW,YAAY,SAAS,CAAC,GAAG;AAClC,yBAAmB,SAAS,CAAC;AAC7B,cAAQ,IAAI,gDAAgD;IAC9D,WAAW,eAAe,YAAY,CAAC,GAAG;AACxC,yBAAmB,YAAY,CAAC;AAChC,cAAQ,IAAI,kDAAkD;IAChE,WAAW,mBAAmB,gBAAgB,CAAC,GAAG;AAChD,yBAAmB,gBAAgB,CAAC;AACpC,cAAQ,IAAI,oCAAoC;IAClD,OAAO;AAEL,YAAM,YAAY,YAAY,MAAM,gCAAgC;AACpE,UAAI,aAAa,UAAU,CAAC,GAAG;AAC7B,YAAI,cAAc,UAAU,CAAC;AAG7B,sBAAc,YACX,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,+BAA+B,EAAE,EACzC,QAAQ,mCAAmC,EAAE,EAC7C,QAAQ,qEAAqE,EAAE,EAC/E,QAAQ,kEAAkE,EAAE,EAC5E,QAAQ,wEAAwE,EAAE;AAErF,2BAAmB;AACnB,gBAAQ,IAAI,uCAAuC;MACrD,OAAO;AAEL,2BAAmB;AACnB,gBAAQ,IAAI,uCAAuC;MACrD;IACF;AAIA,uBAAmB,iBAChB,QAAQ,gBAAgB,SAAS,EACjC,QAAQ,iCAAiC,EAAE,EAC3C,QAAQ,qCAAqC,EAAE,EAC/C,QAAQ,+BAA+B,EAAE;AAG5C,UAAM,cAAc,iBACjB,QAAQ,+BAA+B,UAAU,EACjD,QAAQ,+BAA+B,WAAW,EAClD,QAAQ,+BAA+B,YAAY,EACnD,QAAQ,+BAA+B,aAAa,EACpD,QAAQ,+BAA+B,cAAc,EACrD,QAAQ,+BAA+B,eAAe,EACtD,QAAQ,6BAA6B,QAAQ,EAC7C,QAAQ,gBAAgB,IAAI,EAC5B,QAAQ,+BAA+B,aAAQ,EAC/C,QAAQ,yDAAyD,UAAU,EAC3E,QAAQ,YAAY,EAAE,EACtB,QAAQ,YAAY,MAAM,EAC1B,QAAQ,WAAW,GAAG,EACtB,QAAQ,SAAS,GAAG,EACpB,QAAQ,SAAS,GAAG,EACpB,QAAQ,UAAU,GAAG,EACrB,QAAQ,WAAW,GAAG,EACtB,KAAK;AAGR,UAAM,qBAAqB;AAC3B,UAAM,mBAAmB,YAAY,SAAS,qBAAqB,cAAc;AAGjF,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,SAAS;QACT,SAAS;QACT,KAAK,QAAQ,UAAU,GAAG,GAAG,KAAK,QAAQ,SAAS,MAAM,QAAQ;;MACnE,CAAC;MACD,EAAE,QAAQ;IACZ;EACF,SAAS,OAAO;AACd,YAAQ,MAAM,+BAA+B,KAAK;AAElD,WAAO,IAAI;MACT,KAAK,UAAU;QACb,SAAS;QACT,OAAO,MAAM,WAAW;MAC1B,CAAC;MACD,EAAE,QAAQ,KAAK,QAAQ;IACzB;EACF;AACF;AA/LsBA;AAAAF,QAAAE,YAAA,WAAA;ACAtB,eAAsBA,WAAU,SAAS;AAEvC,MAAI,QAAQ,QAAQ,WAAW,WAAW;AACxC,WAAO,IAAI,SAAS,MAAM;MACxB,SAAS;QACP,+BAA+B;QAC/B,gCAAgC;QAChC,gCAAgC;QAChC,0BAA0B;MAC5B;IACF,CAAC;EACH;AAGA,SAAO,QAAQ,KAAK;AACtB;AAfsBA;AAAAF,QAAAE,YAAA,WAAA;ACaf,IAAM,SAAS;EAClB;IACE,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAAC,aAA8B;EAC1C;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACD,cAAwC;EACpD;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACA,cAAiC;EAC7C;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAAC,gBAAwC;EACpD;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACA,cAAqC;EACjD;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAAC,SAA4B;EACxC;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACC,UAA+B;EAC3C;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACA,UAAiC;EAC7C;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACA,UAAsC;EAClD;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACA,UAA6B;EACzC;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAAC;IACd,SAAS,CAACA,UAA8B;EAC1C;EACF;IACI,WAAW;IACX,WAAW;IACX,QAAQ;IACR,aAAa,CAACA,UAA0B;IACxC,SAAS,CAAC;EACZ;AACF;AC9EF,SAAS,MAAM,KAAW;AACxB,MAAM,SAAqB,CAAA;AAC3B,MAAI,IAAI;AAER,SAAO,IAAI,IAAI,QAAQ;AACrB,QAAM,OAAO,IAAI,CAAC;AAElB,QAAI,SAAS,OAAO,SAAS,OAAO,SAAS,KAAK;AAChD,aAAO,KAAK,EAAE,MAAM,YAAY,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AAC3D;;AAGF,QAAI,SAAS,MAAM;AACjB,aAAO,KAAK,EAAE,MAAM,gBAAgB,OAAO,KAAK,OAAO,IAAI,GAAG,EAAC,CAAE;AACjE;;AAGF,QAAI,SAAS,KAAK;AAChB,aAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AACvD;;AAGF,QAAI,SAAS,KAAK;AAChB,aAAO,KAAK,EAAE,MAAM,SAAS,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AACxD;;AAGF,QAAI,SAAS,KAAK;AAChB,UAAI,OAAO;AACX,UAAI,IAAI,IAAI;AAEZ,aAAO,IAAI,IAAI,QAAQ;AACrB,YAAM,OAAO,IAAI,WAAW,CAAC;AAE7B;;UAEG,QAAQ,MAAM,QAAQ;UAEtB,QAAQ,MAAM,QAAQ;UAEtB,QAAQ,MAAM,QAAQ;UAEvB,SAAS;UACT;AACA,kBAAQ,IAAI,GAAG;AACf;;AAGF;;AAGF,UAAI,CAAC;AAAM,cAAM,IAAI,UAAU,6BAAA,OAA6B,CAAC,CAAE;AAE/D,aAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,KAAI,CAAE;AACnD,UAAI;AACJ;;AAGF,QAAI,SAAS,KAAK;AAChB,UAAI,QAAQ;AACZ,UAAI,UAAU;AACd,UAAI,IAAI,IAAI;AAEZ,UAAI,IAAI,CAAC,MAAM,KAAK;AAClB,cAAM,IAAI,UAAU,oCAAA,OAAoC,CAAC,CAAE;;AAG7D,aAAO,IAAI,IAAI,QAAQ;AACrB,YAAI,IAAI,CAAC,MAAM,MAAM;AACnB,qBAAW,IAAI,GAAG,IAAI,IAAI,GAAG;AAC7B;;AAGF,YAAI,IAAI,CAAC,MAAM,KAAK;AAClB;AACA,cAAI,UAAU,GAAG;AACf;AACA;;mBAEO,IAAI,CAAC,MAAM,KAAK;AACzB;AACA,cAAI,IAAI,IAAI,CAAC,MAAM,KAAK;AACtB,kBAAM,IAAI,UAAU,uCAAA,OAAuC,CAAC,CAAE;;;AAIlE,mBAAW,IAAI,GAAG;;AAGpB,UAAI;AAAO,cAAM,IAAI,UAAU,yBAAA,OAAyB,CAAC,CAAE;AAC3D,UAAI,CAAC;AAAS,cAAM,IAAI,UAAU,sBAAA,OAAsB,CAAC,CAAE;AAE3D,aAAO,KAAK,EAAE,MAAM,WAAW,OAAO,GAAG,OAAO,QAAO,CAAE;AACzD,UAAI;AACJ;;AAGF,WAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;;AAGzD,SAAO,KAAK,EAAE,MAAM,OAAO,OAAO,GAAG,OAAO,GAAE,CAAE;AAEhD,SAAO;AACT;AAvGS;AAAAF,QAAA,OAAA,OAAA;AAuHH,SAAU,MAAM,KAAa,SAA0B;AAA1B,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAA0B;AAC3D,MAAM,SAAS,MAAM,GAAG;AAChB,MAAA,KAAuC,QAAO,UAA9C,WAAQ,OAAA,SAAG,OAAI,IAAE,KAAsB,QAAO,WAA7B,YAAS,OAAA,SAAG,QAAK;AAC1C,MAAM,SAAkB,CAAA;AACxB,MAAI,MAAM;AACV,MAAI,IAAI;AACR,MAAI,OAAO;AAEX,MAAM,aAAa,gBAAAA,QAAA,SAAC,MAAsB;AACxC,QAAI,IAAI,OAAO,UAAU,OAAO,CAAC,EAAE,SAAS;AAAM,aAAO,OAAO,GAAG,EAAE;EACvE,GAFmB,YAAA;AAInB,MAAM,cAAc,gBAAAA,QAAA,SAAC,MAAsB;AACzC,QAAMG,SAAQ,WAAW,IAAI;AAC7B,QAAIA,WAAU;AAAW,aAAOA;AAC1B,QAAAC,MAA4B,OAAO,CAAC,GAA5B,WAAQA,IAAA,MAAE,QAAKA,IAAA;AAC7B,UAAM,IAAI,UAAU,cAAA,OAAc,UAAQ,MAAA,EAAA,OAAO,OAAK,aAAA,EAAA,OAAc,IAAI,CAAE;EAC5E,GALoB,aAAA;AAOpB,MAAM,cAAc,gBAAAJ,QAAA,WAAA;AAClB,QAAIK,UAAS;AACb,QAAIF;AACJ,WAAQA,SAAQ,WAAW,MAAM,KAAK,WAAW,cAAc,GAAI;AACjEE,iBAAUF;;AAEZ,WAAOE;EACT,GAPoB,aAAA;AASpB,MAAM,SAAS,gBAAAL,QAAA,SAACG,QAAa;AAC3B,aAAmB,KAAA,GAAA,cAAA,WAAA,KAAA,YAAA,QAAA,MAAS;AAAvB,UAAMG,QAAI,YAAA,EAAA;AAAe,UAAIH,OAAM,QAAQG,KAAI,IAAI;AAAI,eAAO;;AACnE,WAAO;EACT,GAHe,QAAA;AAKf,MAAM,cAAc,gBAAAN,QAAA,SAACO,SAAc;AACjC,QAAM,OAAO,OAAO,OAAO,SAAS,CAAC;AACrC,QAAM,WAAWA,YAAW,QAAQ,OAAO,SAAS,WAAW,OAAO;AAEtE,QAAI,QAAQ,CAAC,UAAU;AACrB,YAAM,IAAI,UACR,8DAAA,OAA+D,KAAa,MAAI,GAAA,CAAG;;AAIvF,QAAI,CAAC,YAAY,OAAO,QAAQ;AAAG,aAAO,KAAA,OAAK,aAAa,SAAS,GAAC,KAAA;AACtE,WAAO,SAAA,OAAS,aAAa,QAAQ,GAAC,KAAA,EAAA,OAAM,aAAa,SAAS,GAAC,MAAA;EACrE,GAZoB,aAAA;AAcpB,SAAO,IAAI,OAAO,QAAQ;AACxB,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAM,UAAU,WAAW,SAAS;AAEpC,QAAI,QAAQ,SAAS;AACnB,UAAI,SAAS,QAAQ;AAErB,UAAI,SAAS,QAAQ,MAAM,MAAM,IAAI;AACnC,gBAAQ;AACR,iBAAS;;AAGX,UAAI,MAAM;AACR,eAAO,KAAK,IAAI;AAChB,eAAO;;AAGT,aAAO,KAAK;QACV,MAAM,QAAQ;QACd;QACA,QAAQ;QACR,SAAS,WAAW,YAAY,MAAM;QACtC,UAAU,WAAW,UAAU,KAAK;OACrC;AACD;;AAGF,QAAM,QAAQ,QAAQ,WAAW,cAAc;AAC/C,QAAI,OAAO;AACT,cAAQ;AACR;;AAGF,QAAI,MAAM;AACR,aAAO,KAAK,IAAI;AAChB,aAAO;;AAGT,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAI,MAAM;AACR,UAAM,SAAS,YAAW;AAC1B,UAAM,SAAO,WAAW,MAAM,KAAK;AACnC,UAAM,YAAU,WAAW,SAAS,KAAK;AACzC,UAAM,SAAS,YAAW;AAE1B,kBAAY,OAAO;AAEnB,aAAO,KAAK;QACV,MAAM,WAAS,YAAU,QAAQ;QACjC,SAAS,UAAQ,CAAC,YAAU,YAAY,MAAM,IAAI;QAClD;QACA;QACA,UAAU,WAAW,UAAU,KAAK;OACrC;AACD;;AAGF,gBAAY,KAAK;;AAGnB,SAAO;AACT;AA7GgB;AAAAP,QAAA,OAAA,OAAA;AA4PV,SAAU,MACd,KACA,SAAwE;AAExE,MAAM,OAAc,CAAA;AACpB,MAAM,KAAK,aAAa,KAAK,MAAM,OAAO;AAC1C,SAAO,iBAAoB,IAAI,MAAM,OAAO;AAC9C;AAPgB;AAAAA,QAAA,OAAA,OAAA;AAYV,SAAU,iBACd,IACA,MACA,SAAqC;AAArC,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAAqC;AAE7B,MAAA,KAA8B,QAAO,QAArC,SAAM,OAAA,SAAG,SAAC,GAAS;AAAK,WAAA;EAAA,IAAC;AAEjC,SAAO,SAAU,UAAgB;AAC/B,QAAM,IAAI,GAAG,KAAK,QAAQ;AAC1B,QAAI,CAAC;AAAG,aAAO;AAEP,QAAG,OAAgB,EAAC,CAAA,GAAX,QAAU,EAAC;AAC5B,QAAM,SAAS,uBAAO,OAAO,IAAI;mDAExBQ,IAAC;AACR,UAAI,EAAEA,EAAC,MAAM;;AAEb,UAAM,MAAM,KAAKA,KAAI,CAAC;AAEtB,UAAI,IAAI,aAAa,OAAO,IAAI,aAAa,KAAK;AAChD,eAAO,IAAI,IAAI,IAAI,EAAEA,EAAC,EAAE,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,IAAI,SAAC,OAAK;AAC/D,iBAAO,OAAO,OAAO,GAAG;QAC1B,CAAC;aACI;AACL,eAAO,IAAI,IAAI,IAAI,OAAO,EAAEA,EAAC,GAAG,GAAG;;;AAVvC,aAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAG;cAAxB,CAAC;;AAcV,WAAO,EAAE,MAAM,OAAO,OAAM;EAC9B;AACF;AA9BgB;AAAAR,QAAA,kBAAA,kBAAA;AAmChB,SAAS,aAAa,KAAW;AAC/B,SAAO,IAAI,QAAQ,6BAA6B,MAAM;AACxD;AAFS;AAAAA,QAAA,cAAA,cAAA;AAOT,SAAS,MAAM,SAAiC;AAC9C,SAAO,WAAW,QAAQ,YAAY,KAAK;AAC7C;AAFS;AAAAA,QAAA,OAAA,OAAA;AAuBT,SAAS,eAAe,MAAc,MAAY;AAChD,MAAI,CAAC;AAAM,WAAO;AAElB,MAAM,cAAc;AAEpB,MAAI,QAAQ;AACZ,MAAI,aAAa,YAAY,KAAK,KAAK,MAAM;AAC7C,SAAO,YAAY;AACjB,SAAK,KAAK;;MAER,MAAM,WAAW,CAAC,KAAK;MACvB,QAAQ;MACR,QAAQ;MACR,UAAU;MACV,SAAS;KACV;AACD,iBAAa,YAAY,KAAK,KAAK,MAAM;;AAG3C,SAAO;AACT;AApBS;AAAAA,QAAA,gBAAA,gBAAA;AAyBT,SAAS,cACP,OACA,MACA,SAA8C;AAE9C,MAAM,QAAQ,MAAM,IAAI,SAAC,MAAI;AAAK,WAAA,aAAa,MAAM,MAAM,OAAO,EAAE;EAAlC,CAAwC;AAC1E,SAAO,IAAI,OAAO,MAAA,OAAM,MAAM,KAAK,GAAG,GAAC,GAAA,GAAK,MAAM,OAAO,CAAC;AAC5D;AAPS;AAAAA,QAAA,eAAA,eAAA;AAYT,SAAS,eACP,MACA,MACA,SAA8C;AAE9C,SAAO,eAAe,MAAM,MAAM,OAAO,GAAG,MAAM,OAAO;AAC3D;AANS;AAAAA,QAAA,gBAAA,gBAAA;AA0CH,SAAU,eACd,QACA,MACA,SAAmC;AAAnC,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAAmC;AAGjC,MAAA,KAME,QAAO,QANT,SAAM,OAAA,SAAG,QAAK,IACd,KAKE,QAAO,OALT,QAAK,OAAA,SAAG,OAAI,IACZ,KAIE,QAAO,KAJT,MAAG,OAAA,SAAG,OAAI,IACV,KAGE,QAAO,QAHT,SAAM,OAAA,SAAG,SAAC,GAAS;AAAK,WAAA;EAAA,IAAC,IACzB,KAEE,QAAO,WAFT,YAAS,OAAA,SAAG,QAAK,IACjB,KACE,QAAO,UADT,WAAQ,OAAA,SAAG,KAAE;AAEf,MAAM,aAAa,IAAA,OAAI,aAAa,QAAQ,GAAC,KAAA;AAC7C,MAAM,cAAc,IAAA,OAAI,aAAa,SAAS,GAAC,GAAA;AAC/C,MAAI,QAAQ,QAAQ,MAAM;AAG1B,WAAoB,KAAA,GAAA,WAAA,QAAA,KAAA,SAAA,QAAA,MAAQ;AAAvB,QAAM,QAAK,SAAA,EAAA;AACd,QAAI,OAAO,UAAU,UAAU;AAC7B,eAAS,aAAa,OAAO,KAAK,CAAC;WAC9B;AACL,UAAM,SAAS,aAAa,OAAO,MAAM,MAAM,CAAC;AAChD,UAAM,SAAS,aAAa,OAAO,MAAM,MAAM,CAAC;AAEhD,UAAI,MAAM,SAAS;AACjB,YAAI;AAAM,eAAK,KAAK,KAAK;AAEzB,YAAI,UAAU,QAAQ;AACpB,cAAI,MAAM,aAAa,OAAO,MAAM,aAAa,KAAK;AACpD,gBAAM,MAAM,MAAM,aAAa,MAAM,MAAM;AAC3C,qBAAS,MAAA,OAAM,QAAM,MAAA,EAAA,OAAO,MAAM,SAAO,MAAA,EAAA,OAAO,MAAM,EAAA,OAAG,QAAM,KAAA,EAAA,OAAM,MAAM,SAAO,MAAA,EAAA,OAAO,QAAM,GAAA,EAAA,OAAI,GAAG;iBACjG;AACL,qBAAS,MAAA,OAAM,QAAM,GAAA,EAAA,OAAI,MAAM,SAAO,GAAA,EAAA,OAAI,QAAM,GAAA,EAAA,OAAI,MAAM,QAAQ;;eAE/D;AACL,cAAI,MAAM,aAAa,OAAO,MAAM,aAAa,KAAK;AACpD,kBAAM,IAAI,UACR,mBAAA,OAAmB,MAAM,MAAI,+BAAA,CAA+B;;AAIhE,mBAAS,IAAA,OAAI,MAAM,SAAO,GAAA,EAAA,OAAI,MAAM,QAAQ;;aAEzC;AACL,iBAAS,MAAA,OAAM,MAAM,EAAA,OAAG,QAAM,GAAA,EAAA,OAAI,MAAM,QAAQ;;;;AAKtD,MAAI,KAAK;AACP,QAAI,CAAC;AAAQ,eAAS,GAAA,OAAG,aAAW,GAAA;AAEpC,aAAS,CAAC,QAAQ,WAAW,MAAM,MAAA,OAAM,YAAU,GAAA;SAC9C;AACL,QAAM,WAAW,OAAO,OAAO,SAAS,CAAC;AACzC,QAAM,iBACJ,OAAO,aAAa,WAChB,YAAY,QAAQ,SAAS,SAAS,SAAS,CAAC,CAAC,IAAI,KACrD,aAAa;AAEnB,QAAI,CAAC,QAAQ;AACX,eAAS,MAAA,OAAM,aAAW,KAAA,EAAA,OAAM,YAAU,KAAA;;AAG5C,QAAI,CAAC,gBAAgB;AACnB,eAAS,MAAA,OAAM,aAAW,GAAA,EAAA,OAAI,YAAU,GAAA;;;AAI5C,SAAO,IAAI,OAAO,OAAO,MAAM,OAAO,CAAC;AACzC;AAvEgB;AAAAA,QAAA,gBAAA,gBAAA;AAqFV,SAAU,aACd,MACA,MACA,SAA8C;AAE9C,MAAI,gBAAgB;AAAQ,WAAO,eAAe,MAAM,IAAI;AAC5D,MAAI,MAAM,QAAQ,IAAI;AAAG,WAAO,cAAc,MAAM,MAAM,OAAO;AACjE,SAAO,eAAe,MAAM,MAAM,OAAO;AAC3C;AARgB;AAAAA,QAAA,cAAA,cAAA;ACrnBhB,IAAM,cAAc;AAwDpB,UAAU,eAAe,SAAkB;AAC1C,QAAM,cAAc,IAAI,IAAI,QAAQ,GAAG,EAAE;AAGzC,aAAW,SAAS,CAAC,GAAG,MAAM,EAAE,QAAQ,GAAG;AAC1C,QAAI,MAAM,UAAU,MAAM,WAAW,QAAQ,QAAQ;AACpD;IACD;AAGA,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,cAAc,aAAa,WAAW;AAC5C,UAAM,mBAAmB,aAAa,WAAW;AACjD,QAAI,eAAe,kBAAkB;AACpC,iBAAW,WAAW,MAAM,YAAY,KAAK,GAAG;AAC/C,cAAM;UACL;UACA,QAAQ,YAAY;UACpB,MAAM,iBAAiB;QACxB;MACD;IACD;EACD;AAGA,aAAW,SAAS,QAAQ;AAC3B,QAAI,MAAM,UAAU,MAAM,WAAW,QAAQ,QAAQ;AACpD;IACD;AACA,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;MACxE,KAAK;IACN,CAAC;AACD,UAAM,cAAc,aAAa,WAAW;AAC5C,UAAM,mBAAmB,aAAa,WAAW;AACjD,QAAI,eAAe,oBAAoB,MAAM,QAAQ,QAAQ;AAC5D,iBAAW,WAAW,MAAM,QAAQ,KAAK,GAAG;AAC3C,cAAM;UACL;UACA,QAAQ,YAAY;UACpB,MAAM,YAAY;QACnB;MACD;AACA;IACD;EACD;AACD;AArDU;AAAAA,QAAA,gBAAA,gBAAA;AAuDV,IAAO,gCAAQ;EACd,MAAM,MACL,iBACA,KACA,eACC;AACD,QAAI,UAAU;AACd,UAAM,kBAAkB,eAAe,OAAO;AAC9C,QAAI,OAAO,CAAC;AACZ,QAAI,aAAa;AAEjB,UAAM,OAAO,gBAAAA,QAAA,OAAO,OAAqB,SAAuB;AAC/D,UAAI,UAAU,QAAW;AACxB,YAAI,MAAM;AACV,YAAI,OAAO,UAAU,UAAU;AAC9B,gBAAM,IAAI,IAAI,OAAO,QAAQ,GAAG,EAAE,SAAS;QAC5C;AACA,kBAAU,IAAI,QAAQ,KAAK,IAAI;MAChC;AAEA,YAAM,SAAS,gBAAgB,KAAK;AAEpC,UAAI,OAAO,SAAS,OAAO;AAC1B,cAAM,EAAE,SAAS,QAAQ,KAAK,IAAI,OAAO;AACzC,cAAM,UAAU;UACf,SAAS,IAAI,QAAQ,QAAQ,MAAM,CAAC;UACpC,cAAc;UACd;UACA;UACA,IAAI,OAAO;AACV,mBAAO;UACR;UACA,IAAI,KAAK,OAAO;AACf,gBAAI,OAAO,UAAU,YAAY,UAAU,MAAM;AAChD,oBAAM,IAAI,MAAM,gCAAgC;YACjD;AAEA,mBAAO;UACR;UACA;UACA,WAAW,cAAc,UAAU,KAAK,aAAa;UACrD,wBAAwB,gBAAAA,QAAA,MAAM;AAC7B,yBAAa;UACd,GAFwB,wBAAA;QAGzB;AAEA,cAAM,WAAW,MAAM,QAAQ,OAAO;AAEtC,YAAI,EAAE,oBAAoB,WAAW;AACpC,gBAAM,IAAI,MAAM,8CAA8C;QAC/D;AAEA,eAAO,cAAc,QAAQ;MAC9B,WAAW,UAAsB;AAEhC,cAAM,WAAW,MAAM,IAAI,QAAoB,EAAE,MAAM,OAAO;AAC9D,eAAO,cAAc,QAAQ;MAC9B,OAAO;AAEN,cAAM,WAAW,MAAM,MAAM,OAAO;AACpC,eAAO,cAAc,QAAQ;MAC9B;IACD,GAnDa,MAAA;AAqDb,QAAI;AACH,aAAO,MAAM,KAAK;IACnB,SAAS,OAAO;AACf,UAAI,YAAY;AACf,cAAM,WAAW,MAAM,IAAI,QAAoB,EAAE,MAAM,OAAO;AAC9D,eAAO,cAAc,QAAQ;MAC9B;AAEA,YAAM;IACP;EACD;AACD;AAGA,IAAM,gBAAgB,gBAAAA,QAAA,CAAC;;EAEtB,IAAI;IACH,CAAC,KAAK,KAAK,KAAK,GAAG,EAAE,SAAS,SAAS,MAAM,IAAI,OAAO,SAAS;IACjE;EACD;GALqB,eAAA;AC9LtB,IAAM,YAAwB,gBAAAA,QAAA,OAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;EAC7C,UAAA;AACC,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;QAAC;MACtC;IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;IAC5D;EACD;AACD,GAb8B,WAAA;AAe9B,IAAO,6CAAQ;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;IACN,MAAM,GAAG;IACT,SAAS,GAAG,WAAW,OAAO,CAAC;IAC/B,OAAO,GAAG;IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;EAChE;AACD;AAPS;AAAAA,QAAA,aAAA,aAAA;AAUT,IAAM,YAAwB,gBAAAA,QAAA,OAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;MAC3B,QAAQ;MACR,SAAS,EAAE,+BAA+B,OAAO;IAClD,CAAC;EACF;AACD,GAV8B,WAAA;AAY9B,IAAO,2CAAQ;ACzBJ,IAAM,mCAAmC;EAE9B;EAAyB;AAC3C;AACA,IAAO,sCAAQ;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAAAA,QAAA,qBAAA,qBAAA;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;IACxC;IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;IACtE;EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAAAA,QAAA,wBAAA,wBAAA;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;IAC1D,GAAG;IACH;EACD,CAAC;AACF;AAXgB;AAAAA,QAAA,mBAAA,mBAAA;AC3ChB,IAAM,iCAAN,MAAM,gCAA8D;SAAA;;;EAGnE,YACU,eACA,MACT,SACC;AAHQ,SAAA,gBAAA;AACA,SAAA,OAAA;AAGT,SAAK,WAAW;EACjB;EArBD,OAYoE;AAAA,IAAAA,QAAA,MAAA,gCAAA;EAAA;EAC1D;EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,kCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;IACzC;AAEA,SAAK,SAAS;EACf;AACD;AAEA,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;EAC/B;AAEA,QAAM,kBAA+C,gBAAAA,QAAA,SACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;EACtC,GATqD,iBAAA;AAWrD,SAAO;IACN,GAAG;IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gBAAAA,QAAA,SAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;YACtB,KAAK,IAAI;YACT,KAAK,QAAQ;YACb,MAAM;YAAC;UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;QAC7C;MACD,GAT+B,YAAA;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;IACxE;EACD;AACD;AAxCS;AAAAA,QAAA,qBAAA,qBAAA;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;EAC/B;AAGA,SAAO,cAAc,MAAM;IAC1B,mBAAyE,gBAAAA,QAAA,CACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;MACvE;AACA,aAAO,MAAM,MAAM,OAAO;IAC3B,GAXyE,kBAAA;IAazE,cAA0B,gBAAAA,QAAA,CAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;UACtB,KAAK,IAAI;UACT,KAAK,QAAQ;UACb,MAAM;UAAC;QACR;AACA,eAAO,MAAM,UAAU,UAAU;MAClC;IACD,GAT0B,aAAA;IAW1B,MAAM,SAAwD;AAC7D,aAAO;QACN;QACA,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;MACN;IACD;EACD;AACD;AAnDS;AAAAA,QAAA,sBAAA,sBAAA;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;;;ACnIf,IAAMS,aAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAOC,8CAAQD;;;ACRf,SAASE,aAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAYA,aAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS,OAAAA,cAAA;AAUT,IAAMC,aAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQD,aAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAOE,4CAAQD;;;ACzBJ,IAAME,oCAAmC;AAAA,EAE9BC;AAAA,EAAyBC;AAC3C;AACA,IAAOC,uCAAQ;;;ACcnB,IAAMC,yBAAsC,CAAC;AAKtC,SAASC,wBAAuB,MAAqC;AAC3E,EAAAD,uBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB,OAAAC,sBAAA;AAShB,SAASC,wBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAOA,wBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS,OAAAA,yBAAA;AAiBF,SAASC,mBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAOD,wBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAGE;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB,OAAAD,oBAAA;;;AC3ChB,IAAME,kCAAN,MAAMC,iCAA8D;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EArBD,OAYoE;AAAA;AAAA;AAAA,EAC1D;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgBA,mCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAEA,SAASC,qBAAoB,QAA0C;AAEtE,MACCC,sCAAqC,UACrCA,kCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAcA,mCAAkC;AAC1D,IAAAC,qBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAIJ;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAOK,mBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS,OAAAH,sBAAA;AA0CT,SAASI,sBACR,OAC8B;AAE9B,MACCH,sCAAqC,UACrCA,kCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAcA,mCAAkC;AAC1D,IAAAC,qBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,wBACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B,GAXyE;AAAA,IAazE,cAA0B,wBAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAIJ;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD,GAT0B;AAAA,IAW1B,MAAM,SAAwD;AAC7D,aAAOK;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS,OAAAC,uBAAA;AAqDT,IAAIC;AACJ,IAAI,OAAOC,yCAAU,UAAU;AAC9B,EAAAD,iBAAgBL,qBAAoBM,oCAAK;AAC1C,WAAW,OAAOA,yCAAU,YAAY;AACvC,EAAAD,iBAAgBD,sBAAqBE,oCAAK;AAC3C;AACA,IAAOC,mCAAQF;",
  "names": ["urls", "checkURL", "__name", "onRequestPost", "onRequest", "value", "_a", "result", "char", "prefix", "i", "drainBody", "middleware_ensure_req_body_drained_default", "reduceError", "jsonError", "middleware_miniflare3_json_error_default", "__INTERNAL_WRANGLER_MIDDLEWARE__", "middleware_ensure_req_body_drained_default", "middleware_miniflare3_json_error_default", "middleware_insertion_facade_default", "__facade_middleware__", "__facade_register__", "__facade_invokeChain__", "__facade_invoke__", "__facade_middleware__", "__Facade_ScheduledController__", "___Facade_ScheduledController__", "wrapExportedHandler", "__INTERNAL_WRANGLER_MIDDLEWARE__", "__facade_register__", "__facade_invoke__", "wrapWorkerEntrypoint", "WRAPPED_ENTRY", "middleware_insertion_facade_default", "middleware_loader_entry_default"]
}
